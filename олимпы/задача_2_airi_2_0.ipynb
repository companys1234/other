{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mW-ERIYwAHeA",
        "outputId": "20e5ec49-6847-41a8-e37a-b43bb89c2f2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded white points from CSV: 570 entries\n",
            "Common files: 0\n",
            "Dataset created: 0 images, 0 histograms\n",
            "Error: No valid samples found in dataset!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class ImageHistogramDataset(Dataset):\n",
        "    \"\"\"–î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º\"\"\"\n",
        "\n",
        "    def __init__(self, images_dir, histograms_dir, csv_path=None, transform=None, img_size=512):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            images_dir (str): –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏\n",
        "            histograms_dir (str): –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞–º–∏\n",
        "            csv_path (str, optional): –ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É —Å —Ç–æ—á–∫–∞–º–∏ –±–µ–ª–æ–≥–æ\n",
        "            transform (callable, optional): –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º—ã –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
        "            img_size (int): –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è resize\n",
        "        \"\"\"\n",
        "        self.images_dir = Path(images_dir)\n",
        "        self.histograms_dir = Path(histograms_dir)\n",
        "        self.transform = transform\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø–∞–ø–æ–∫\n",
        "        \"\"\"if not self.images_dir.exists():\n",
        "            raise ValueError(f\"Images directory not found: {images_dir}\")\n",
        "        if not self.histograms_dir.exists():\n",
        "            raise ValueError(f\"Histograms directory not found: {histograms_dir}\")\"\"\"\n",
        "\n",
        "        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤\n",
        "        self.image_files = self._get_image_files()\n",
        "        self.histogram_files = self._get_histogram_files()\n",
        "\n",
        "        # –ó–∞–≥—Ä—É–∂–∞–µ–º white points –∏–∑ CSV –µ—Å–ª–∏ –µ—Å—Ç—å\n",
        "        self.white_points = self._load_white_points(csv_path)\n",
        "\n",
        "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ñ–∞–π–ª–æ–≤\n",
        "        self._validate_files()\n",
        "\n",
        "        print(f\"Dataset created: {len(self.image_files)} images, {len(self.histogram_files)} histograms\")\n",
        "\n",
        "    def _get_image_files(self):\n",
        "        \"\"\"–ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\"\"\"\n",
        "        image_extensions = ['.png', '.jpg', '.jpeg', '.tiff', '.tif', '.bmp']\n",
        "        image_files = []\n",
        "\n",
        "        for ext in image_extensions:\n",
        "            image_files.extend(list(self.images_dir.glob(f'*{ext}')))\n",
        "            image_files.extend(list(self.images_dir.glob(f'*{ext.upper()}')))\n",
        "\n",
        "        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∏–º–µ–Ω–∏ –¥–ª—è consistency\n",
        "        image_files.sort(key=lambda x: x.name)\n",
        "        return image_files\n",
        "\n",
        "    def _get_histogram_files(self):\n",
        "        \"\"\"–ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º\"\"\"\n",
        "        histogram_extensions = ['.png', '.jpg', '.jpeg', '.npy']\n",
        "        histogram_files = []\n",
        "\n",
        "        for ext in histogram_extensions:\n",
        "            histogram_files.extend(list(self.histograms_dir.glob(f'*{ext}')))\n",
        "            histogram_files.extend(list(self.histograms_dir.glob(f'*{ext.upper()}')))\n",
        "\n",
        "        histogram_files.sort(key=lambda x: x.name)\n",
        "        return histogram_files\n",
        "\n",
        "    def _load_white_points(self, csv_path):\n",
        "        \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ—á–∫–∏ –±–µ–ª–æ–≥–æ –∏–∑ CSV\"\"\"\n",
        "        white_points = {}\n",
        "\n",
        "        if csv_path and os.path.exists(csv_path):\n",
        "            try:\n",
        "                df = pd.read_csv(csv_path)\n",
        "                print(f\"Loaded white points from CSV: {len(df)} entries\")\n",
        "\n",
        "                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏\n",
        "                image_col = None\n",
        "                wp_cols = ['wp_r', 'wp_g', 'wp_b']\n",
        "\n",
        "                for col in df.columns:\n",
        "                    if 'image' in col.lower() or 'path' in col.lower() or 'name' in col.lower():\n",
        "                        image_col = col\n",
        "                        break\n",
        "\n",
        "                if image_col is None:\n",
        "                    image_col = df.columns[0]\n",
        "\n",
        "                # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å {filename: [wp_r, wp_g, wp_b]}\n",
        "                for _, row in df.iterrows():\n",
        "                    filename = Path(row[image_col]).name\n",
        "                    wp_values = [row.get(col, 32768.0) for col in wp_cols]\n",
        "                    white_points[filename] = wp_values\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading CSV: {e}\")\n",
        "\n",
        "        return white_points\n",
        "\n",
        "    def _validate_files(self):\n",
        "        \"\"\"–ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º\"\"\"\n",
        "        # –ü–æ–ª—É—á–∞–µ–º –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π\n",
        "        image_names = {f.stem for f in self.image_files}\n",
        "        histogram_names = {f.stem for f in self.histogram_files}\n",
        "\n",
        "        # –û–±—â–∏–µ —Ñ–∞–π–ª—ã\n",
        "        common_names = image_names & histogram_names\n",
        "        print(f\"Common files: {len(common_names)}\")\n",
        "\n",
        "        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã\n",
        "        self.image_files = [f for f in self.image_files if f.stem in common_names]\n",
        "        self.histogram_files = [f for f in self.histogram_files if f.stem in common_names]\n",
        "\n",
        "        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —á—Ç–æ–±—ã –ø–æ—Ä—è–¥–æ–∫ —Å–æ–≤–ø–∞–¥–∞–ª\n",
        "        self.image_files.sort(key=lambda x: x.stem)\n",
        "        self.histogram_files.sort(key=lambda x: x.stem)\n",
        "\n",
        "    def _read_image(self, image_path):\n",
        "        \"\"\"–ß—Ç–µ–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\"\"\"\n",
        "        try:\n",
        "            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã —á—Ç–µ–Ω–∏—è\n",
        "            img = cv2.imread(str(image_path), cv2.IMREAD_UNCHANGED)\n",
        "            if img is None:\n",
        "                img = cv2.imread(str(image_path), cv2.IMREAD_COLOR)\n",
        "\n",
        "            if img is None:\n",
        "                raise ValueError(f\"Cannot read image: {image_path}\")\n",
        "\n",
        "            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ float –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º\n",
        "            if img.dtype == np.uint16:\n",
        "                img = img.astype(np.float32) / 65535.0\n",
        "            elif img.dtype == np.uint8:\n",
        "                img = img.astype(np.float32) / 255.0\n",
        "\n",
        "            # BGR to RGB\n",
        "            if img.shape[-1] == 3:\n",
        "                img = img[..., ::-1]\n",
        "\n",
        "            # Resize\n",
        "            if img.shape[0] != self.img_size or img.shape[1] != self.img_size:\n",
        "                img = cv2.resize(img, (self.img_size, self.img_size))\n",
        "\n",
        "            return img\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading image {image_path}: {e}\")\n",
        "            return np.zeros((self.img_size, self.img_size, 3), dtype=np.float32)\n",
        "\n",
        "    def _read_histogram(self, histogram_path):\n",
        "        \"\"\"–ß—Ç–µ–Ω–∏–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã\"\"\"\n",
        "        try:\n",
        "            if histogram_path.suffix.lower() in ['.npy']:\n",
        "                hist = np.load(histogram_path)\n",
        "            else:\n",
        "                hist = cv2.imread(str(histogram_path), cv2.IMREAD_GRAYSCALE)\n",
        "                if hist is None:\n",
        "                    hist = np.zeros((128, 128), dtype=np.float32)\n",
        "                else:\n",
        "                    hist = hist.astype(np.float32) / 255.0\n",
        "\n",
        "            return hist\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading histogram {histogram_path}: {e}\")\n",
        "            return np.zeros((128, 128), dtype=np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            image_path = self.image_files[idx]\n",
        "            histogram_path = self.histogram_files[idx]\n",
        "\n",
        "            # –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
        "            image = self._read_image(image_path)\n",
        "            histogram = self._read_histogram(histogram_path)\n",
        "\n",
        "            # White point\n",
        "            filename = image_path.stem\n",
        "            if filename in self.white_points:\n",
        "                wp_r, wp_g, wp_b = self.white_points[filename]\n",
        "            else:\n",
        "                wp_r, wp_g, wp_b = 32768.0, 32768.0, 32768.0\n",
        "\n",
        "            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è white point –∫ [0, 1]\n",
        "            white_point = np.array([wp_r, wp_g, wp_b], dtype=np.float32) / 65535.0\n",
        "\n",
        "            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ tensor\n",
        "            image_tensor = torch.from_numpy(image.transpose(2, 0, 1)).float()\n",
        "            hist_tensor = torch.from_numpy(histogram).float().unsqueeze(0)  # –î–æ–±–∞–≤–ª—è–µ–º channel dimension\n",
        "            wp_tensor = torch.from_numpy(white_point).float()\n",
        "\n",
        "            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º—ã\n",
        "            if self.transform:\n",
        "                image_tensor = self.transform(image_tensor)\n",
        "\n",
        "            return image_tensor, hist_tensor, wp_tensor\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading sample {idx}: {e}\")\n",
        "            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º dummy –¥–∞–Ω–Ω—ã–µ\n",
        "            dummy_image = torch.randn(3, self.img_size, self.img_size)\n",
        "            dummy_hist = torch.zeros(1, 128, 128)\n",
        "            dummy_wp = torch.tensor([0.5, 0.5, 0.5])\n",
        "            return dummy_image, dummy_hist, dummy_wp\n",
        "\n",
        "def create_data_loaders(images_dir, histograms_dir, csv_path=None,\n",
        "                       batch_size=8, val_size=0.2, img_size=512, transform=None):\n",
        "    \"\"\"–°–æ–∑–¥–∞–µ—Ç DataLoader'—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\"\"\"\n",
        "\n",
        "    # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç\n",
        "    dataset = ImageHistogramDataset(\n",
        "        images_dir=images_dir,\n",
        "        histograms_dir=histograms_dir,\n",
        "        csv_path=csv_path,\n",
        "        transform=transform,\n",
        "        img_size=img_size\n",
        "    )\n",
        "\n",
        "    if len(dataset) == 0:\n",
        "        raise ValueError(\"No valid samples found in dataset!\")\n",
        "\n",
        "    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val\n",
        "    indices = list(range(len(dataset)))\n",
        "    train_indices, val_indices = train_test_split(\n",
        "        indices, test_size=val_size, random_state=42, shuffle=True\n",
        "    )\n",
        "\n",
        "    # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–≤—ã–±–æ—Ä–∫–∏\n",
        "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
        "    val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
        "\n",
        "    print(f\"Train samples: {len(train_indices)}, Val samples: {len(val_indices)}\")\n",
        "\n",
        "    # DataLoaders\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=min(batch_size, len(train_dataset)),\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=min(batch_size, len(val_dataset)),\n",
        "        shuffle=False,\n",
        "        num_workers=1,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
        "def example_usage():\n",
        "    \"\"\"–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞\"\"\"\n",
        "\n",
        "    # –ü—É—Ç–∏ –∫ –≤–∞—à–∏–º –ø–∞–ø–∫–∞–º\n",
        "    IMAGES_DIR = \"/content/train_imgs\"\n",
        "    HISTOGRAMS_DIR = \"/content/train_histograms\"\n",
        "    CSV_PATH = \"/content/train.csv\"\n",
        "\n",
        "    try:\n",
        "        # –°–æ–∑–¥–∞–µ–º DataLoader'—ã\n",
        "        train_loader, val_loader = create_data_loaders(\n",
        "            images_dir=IMAGES_DIR,\n",
        "            histograms_dir=HISTOGRAMS_DIR,\n",
        "            csv_path=CSV_PATH,\n",
        "            batch_size=8,\n",
        "            val_size=0.2,\n",
        "            img_size=512\n",
        "        )\n",
        "\n",
        "        print(f\"Successfully created data loaders!\")\n",
        "        print(f\"Train batches: {len(train_loader)}\")\n",
        "        print(f\"Val batches: {len(val_loader)}\")\n",
        "\n",
        "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–π –±–∞—Ç—á\n",
        "        for images, hists, white_points in train_loader:\n",
        "            print(f\"Images shape: {images.shape}\")\n",
        "            print(f\"Histograms shape: {hists.shape}\")\n",
        "            print(f\"White points shape: {white_points.shape}\")\n",
        "            print(f\"White points range: {white_points.min():.3f} - {white_points.max():.3f}\")\n",
        "            break\n",
        "\n",
        "        return train_loader, val_loader\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
        "def check_folder_structure(images_dir, histograms_dir):\n",
        "    \"\"\"–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫\"\"\"\n",
        "    print(\"üîç Checking folder structure...\")\n",
        "\n",
        "    images_dir = Path(images_dir)\n",
        "    histograms_dir = Path(histograms_dir)\n",
        "\n",
        "    print(f\"Images directory: {images_dir}\")\n",
        "    if images_dir.exists():\n",
        "        image_files = list(images_dir.glob('*.*'))\n",
        "        print(f\"  Found {len(image_files)} files\")\n",
        "        if image_files:\n",
        "            print(f\"  Example: {image_files[0].name}\")\n",
        "    else:\n",
        "        print(\"  ‚ùå Does not exist!\")\n",
        "\n",
        "    print(f\"Histograms directory: {histograms_dir}\")\n",
        "    if histograms_dir.exists():\n",
        "        hist_files = list(histograms_dir.glob('*.*'))\n",
        "        print(f\"  Found {len(hist_files)} files\")\n",
        "        if hist_files:\n",
        "            print(f\"  Example: {hist_files[0].name}\")\n",
        "    else:\n",
        "        print(\"  ‚ùå Does not exist!\")\n",
        "\n",
        "# –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç\n",
        "def quick_start():\n",
        "    \"\"\"–ë—ã—Å—Ç—Ä–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞\"\"\"\n",
        "    # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à–∏ –ø—É—Ç–∏\n",
        "    images_dir = input(\"Enter images directory path: \").strip() or \"/content/train_imgs\"\n",
        "    histograms_dir = input(\"Enter histograms directory path: \").strip() or \"/content/train_histograms\"\n",
        "    csv_path = input(\"Enter CSV path (optional): \").strip() or None\n",
        "\n",
        "    check_folder_structure(images_dir, histograms_dir)\n",
        "\n",
        "    return create_data_loaders(images_dir, histograms_dir, csv_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # –ó–∞–ø—É—Å–∫ –ø—Ä–∏–º–µ—Ä–∞\n",
        "    train_loader, val_loader = example_usage()\n",
        "\n",
        "    # –ò–ª–∏ –±—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç\n",
        "    # train_loader, val_loader = quick_start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class ImageHistogramDataset(Dataset):\n",
        "    \"\"\"–î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º\"\"\"\n",
        "\n",
        "    def __init__(self, images_dir, histograms_dir, csv_path=None, transform=None, img_size=512):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            images_dir (str): –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏\n",
        "            histograms_dir (str): –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞–º–∏\n",
        "            csv_path (str, optional): –ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É —Å —Ç–æ—á–∫–∞–º–∏ –±–µ–ª–æ–≥–æ\n",
        "            transform (callable, optional): –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º—ã –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
        "            img_size (int): –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è resize\n",
        "        \"\"\"\n",
        "        self.images_dir = Path(images_dir)\n",
        "        self.histograms_dir = Path(histograms_dir)\n",
        "        self.transform = transform\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø–∞–ø–æ–∫\n",
        "        if not self.images_dir.exists():\n",
        "            raise ValueError(f\"Images directory not found: {images_dir}\")\n",
        "        if not self.histograms_dir.exists():\n",
        "            raise ValueError(f\"Histograms directory not found: {histograms_dir}\")\n",
        "\n",
        "        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤\n",
        "        self.image_files = self._get_image_files()\n",
        "        self.histogram_files = self._get_histogram_files()\n",
        "\n",
        "        # –ó–∞–≥—Ä—É–∂–∞–µ–º white points –∏–∑ CSV –µ—Å–ª–∏ –µ—Å—Ç—å\n",
        "        self.white_points = self._load_white_points(csv_path)\n",
        "\n",
        "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ñ–∞–π–ª–æ–≤\n",
        "        self._validate_files()\n",
        "\n",
        "        print(f\"Dataset created: {len(self.image_files)} images, {len(self.histogram_files)} histograms\")\n",
        "\n",
        "    def _get_image_files(self):\n",
        "        \"\"\"–ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\"\"\"\n",
        "        image_extensions = ['.png', '.jpg', '.jpeg', '.tiff', '.tif', '.bmp']\n",
        "        image_files = []\n",
        "\n",
        "        for ext in image_extensions:\n",
        "            image_files.extend(list(self.images_dir.glob(f'*{ext}')))\n",
        "            image_files.extend(list(self.images_dir.glob(f'*{ext.upper()}')))\n",
        "\n",
        "        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∏–º–µ–Ω–∏ –¥–ª—è consistency\n",
        "        image_files.sort(key=lambda x: x.name)\n",
        "        return image_files\n",
        "\n",
        "    def _get_histogram_files(self):\n",
        "        \"\"\"–ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º\"\"\"\n",
        "        histogram_extensions = ['.png', '.jpg', '.jpeg', '.npy']\n",
        "        histogram_files = []\n",
        "\n",
        "        for ext in histogram_extensions:\n",
        "            histogram_files.extend(list(self.histograms_dir.glob(f'*{ext}')))\n",
        "            histogram_files.extend(list(self.histograms_dir.glob(f'*{ext.upper()}')))\n",
        "\n",
        "        histogram_files.sort(key=lambda x: x.name)\n",
        "        return histogram_files\n",
        "\n",
        "    def _load_white_points(self, csv_path):\n",
        "        \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ—á–∫–∏ –±–µ–ª–æ–≥–æ –∏–∑ CSV\"\"\"\n",
        "        white_points = {}\n",
        "\n",
        "        if csv_path and os.path.exists(csv_path):\n",
        "            try:\n",
        "                df = pd.read_csv(csv_path)\n",
        "                print(f\"Loaded white points from CSV: {len(df)} entries\")\n",
        "\n",
        "                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏\n",
        "                image_col = None\n",
        "                wp_cols = ['wp_r', 'wp_g', 'wp_b']\n",
        "\n",
        "                for col in df.columns:\n",
        "                    if 'image' in col.lower() or 'path' in col.lower() or 'name' in col.lower():\n",
        "                        image_col = col\n",
        "                        break\n",
        "\n",
        "                if image_col is None:\n",
        "                    image_col = df.columns[0]\n",
        "\n",
        "                # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å {filename: [wp_r, wp_g, wp_b]}\n",
        "                for _, row in df.iterrows():\n",
        "                    filename = Path(row[image_col]).name\n",
        "                    wp_values = [row.get(col, 32768.0) for col in wp_cols]\n",
        "                    white_points[filename] = wp_values\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading CSV: {e}\")\n",
        "\n",
        "        return white_points\n",
        "\n",
        "    def _validate_files(self):\n",
        "        \"\"\"–ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º\"\"\"\n",
        "        # –ü–æ–ª—É—á–∞–µ–º –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π\n",
        "        image_names = {f.stem for f in self.image_files}\n",
        "        histogram_names = {f.stem for f in self.histogram_files}\n",
        "\n",
        "        # –û–±—â–∏–µ —Ñ–∞–π–ª—ã\n",
        "        common_names = image_names & histogram_names\n",
        "        print(f\"Common files: {len(common_names)}\")\n",
        "\n",
        "        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã\n",
        "        self.image_files = [f for f in self.image_files if f.stem in common_names]\n",
        "        self.histogram_files = [f for f in self.histogram_files if f.stem in common_names]\n",
        "\n",
        "        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —á—Ç–æ–±—ã –ø–æ—Ä—è–¥–æ–∫ —Å–æ–≤–ø–∞–¥–∞–ª\n",
        "        self.image_files.sort(key=lambda x: x.stem)\n",
        "        self.histogram_files.sort(key=lambda x: x.stem)\n",
        "\n",
        "    def _read_image(self, image_path):\n",
        "        \"\"\"–ß—Ç–µ–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\"\"\"\n",
        "        try:\n",
        "            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã —á—Ç–µ–Ω–∏—è\n",
        "            img = cv2.imread(str(image_path), cv2.IMREAD_UNCHANGED)\n",
        "            if img is None:\n",
        "                img = cv2.imread(str(image_path), cv2.IMREAD_COLOR)\n",
        "\n",
        "            if img is None:\n",
        "                raise ValueError(f\"Cannot read image: {image_path}\")\n",
        "\n",
        "            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ float –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º\n",
        "            if img.dtype == np.uint16:\n",
        "                img = img.astype(np.float32) / 65535.0\n",
        "            elif img.dtype == np.uint8:\n",
        "                img = img.astype(np.float32) / 255.0\n",
        "\n",
        "            # BGR to RGB\n",
        "            if img.shape[-1] == 3:\n",
        "                img = img[..., ::-1]\n",
        "\n",
        "            # Resize\n",
        "            if img.shape[0] != self.img_size or img.shape[1] != self.img_size:\n",
        "                img = cv2.resize(img, (self.img_size, self.img_size))\n",
        "\n",
        "            return img\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading image {image_path}: {e}\")\n",
        "            return np.zeros((self.img_size, self.img_size, 3), dtype=np.float32)\n",
        "\n",
        "    def _read_histogram(self, histogram_path):\n",
        "        \"\"\"–ß—Ç–µ–Ω–∏–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã\"\"\"\n",
        "        try:\n",
        "            if histogram_path.suffix.lower() in ['.npy']:\n",
        "                hist = np.load(histogram_path)\n",
        "            else:\n",
        "                hist = cv2.imread(str(histogram_path), cv2.IMREAD_GRAYSCALE)\n",
        "                if hist is None:\n",
        "                    hist = np.zeros((128, 128), dtype=np.float32)\n",
        "                else:\n",
        "                    hist = hist.astype(np.float32) / 255.0\n",
        "\n",
        "            return hist\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading histogram {histogram_path}: {e}\")\n",
        "            return np.zeros((128, 128), dtype=np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            image_path = self.image_files[idx]\n",
        "            histogram_path = self.histogram_files[idx]\n",
        "\n",
        "            # –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
        "            image = self._read_image(image_path)\n",
        "            histogram = self._read_histogram(histogram_path)\n",
        "\n",
        "            # White point\n",
        "            filename = image_path.stem\n",
        "            if filename in self.white_points:\n",
        "                wp_r, wp_g, wp_b = self.white_points[filename]\n",
        "            else:\n",
        "                wp_r, wp_g, wp_b = 32768.0, 32768.0, 32768.0\n",
        "\n",
        "            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è white point –∫ [0, 1]\n",
        "            white_point = np.array([wp_r, wp_g, wp_b], dtype=np.float32) / 65535.0\n",
        "\n",
        "            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ tensor\n",
        "            image_tensor = torch.from_numpy(image.transpose(2, 0, 1)).float()\n",
        "            hist_tensor = torch.from_numpy(histogram).float().unsqueeze(0)  # –î–æ–±–∞–≤–ª—è–µ–º channel dimension\n",
        "            wp_tensor = torch.from_numpy(white_point).float()\n",
        "\n",
        "            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º—ã\n",
        "            if self.transform:\n",
        "                image_tensor = self.transform(image_tensor)\n",
        "\n",
        "            return image_tensor, hist_tensor, wp_tensor\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading sample {idx}: {e}\")\n",
        "            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º dummy –¥–∞–Ω–Ω—ã–µ\n",
        "            dummy_image = torch.randn(3, self.img_size, self.img_size)\n",
        "            dummy_hist = torch.zeros(1, 128, 128)\n",
        "            dummy_wp = torch.tensor([0.5, 0.5, 0.5])\n",
        "            return dummy_image, dummy_hist, dummy_wp\n",
        "\n",
        "def create_data_loaders(images_dir, histograms_dir, csv_path=None,\n",
        "                       batch_size=8, val_size=0.2, img_size=512, transform=None):\n",
        "    \"\"\"–°–æ–∑–¥–∞–µ—Ç DataLoader'—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\"\"\"\n",
        "\n",
        "    # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç\n",
        "    dataset = ImageHistogramDataset(\n",
        "        images_dir=images_dir,\n",
        "        histograms_dir=histograms_dir,\n",
        "        csv_path=csv_path,\n",
        "        transform=transform,\n",
        "        img_size=img_size\n",
        "    )\n",
        "\n",
        "    if len(dataset) == 0:\n",
        "        raise ValueError(\"No valid samples found in dataset!\")\n",
        "\n",
        "    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val\n",
        "    indices = list(range(len(dataset)))\n",
        "    train_indices, val_indices = train_test_split(\n",
        "        indices, test_size=val_size, random_state=42, shuffle=True\n",
        "    )\n",
        "\n",
        "    # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–≤—ã–±–æ—Ä–∫–∏\n",
        "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
        "    val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
        "\n",
        "    print(f\"Train samples: {len(train_indices)}, Val samples: {len(val_indices)}\")\n",
        "\n",
        "    # DataLoaders\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=min(batch_size, len(train_dataset)),\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=min(batch_size, len(val_dataset)),\n",
        "        shuffle=False,\n",
        "        num_workers=1,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
        "def example_usage():\n",
        "    \"\"\"–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞\"\"\"\n",
        "\n",
        "    # –ü—É—Ç–∏ –∫ –≤–∞—à–∏–º –ø–∞–ø–∫–∞–º\n",
        "    IMAGES_DIR = \"/content/train_imgs\"\n",
        "    HISTOGRAMS_DIR = \"/content/–µ–∫—Ñ—à—Ç_—Ä—à—ã–µ—â–ø–∫—Ñ—å—ã2\"\n",
        "    CSV_PATH = \"/content/train.csv\"\n",
        "\n",
        "    try:\n",
        "        # –°–æ–∑–¥–∞–µ–º DataLoader'—ã\n",
        "        train_loader, val_loader = create_data_loaders(\n",
        "            images_dir='/content/train_imgs2',\n",
        "            histograms_dir='/content/train_histograms',\n",
        "            csv_path=\"/content/train.csv\",\n",
        "            batch_size=8,\n",
        "            val_size=0.2,\n",
        "            img_size=512\n",
        "        )\n",
        "\n",
        "        print(f\"Successfully created data loaders!\")\n",
        "        print(f\"Train batches: {len(train_loader)}\")\n",
        "        print(f\"Val batches: {len(val_loader)}\")\n",
        "\n",
        "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–π –±–∞—Ç—á\n",
        "        for images, hists, white_points in train_loader:\n",
        "            print(f\"Images shape: {images.shape}\")\n",
        "            print(f\"Histograms shape: {hists.shape}\")\n",
        "            print(f\"White points shape: {white_points.shape}\")\n",
        "            print(f\"White points range: {white_points.min():.3f} - {white_points.max():.3f}\")\n",
        "            break\n",
        "\n",
        "        return train_loader, val_loader\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
        "def check_folder_structure(images_dir, histograms_dir):\n",
        "    \"\"\"–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫\"\"\"\n",
        "    print(\"üîç Checking folder structure...\")\n",
        "\n",
        "    images_dir = Path(images_dir)\n",
        "    histograms_dir = Path(histograms_dir)\n",
        "\n",
        "    print(f\"Images directory: {images_dir}\")\n",
        "    if images_dir.exists():\n",
        "        image_files = list(images_dir.glob('*.*'))\n",
        "        print(f\"  Found {len(image_files)} files\")\n",
        "        if image_files:\n",
        "            print(f\"  Example: {image_files[0].name}\")\n",
        "    else:\n",
        "        print(\"  ‚ùå Does not exist!\")\n",
        "\n",
        "    print(f\"Histograms directory: {histograms_dir}\")\n",
        "    if histograms_dir.exists():\n",
        "        hist_files = list(histograms_dir.glob('*.*'))\n",
        "        print(f\"  Found {len(hist_files)} files\")\n",
        "        if hist_files:\n",
        "            print(f\"  Example: {hist_files[0].name}\")\n",
        "    else:\n",
        "        print(\"  ‚ùå Does not exist!\")\n",
        "\n",
        "# –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç\n",
        "def quick_start():\n",
        "    \"\"\"–ë—ã—Å—Ç—Ä–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞\"\"\"\n",
        "    # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à–∏ –ø—É—Ç–∏\n",
        "    images_dir = input(\"Enter images directory path: \").strip() or \"/content/train_imgs\"\n",
        "    histograms_dir = input(\"Enter histograms directory path: \").strip() or \"/content/train_histograms\"\n",
        "    csv_path = input(\"Enter CSV path (optional): \").strip() or None\n",
        "\n",
        "    check_folder_structure(images_dir, histograms_dir)\n",
        "\n",
        "    return create_data_loaders(images_dir, histograms_dir, csv_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # –ó–∞–ø—É—Å–∫ –ø—Ä–∏–º–µ—Ä–∞\n",
        "    train_loader, val_loader = example_usage()\n",
        "\n",
        "    # –ò–ª–∏ –±—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç\n",
        "    # train_loader, val_loader = quick_start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgaTKaMPYHDU",
        "outputId": "b51cba49-e802-4da8-d98d-a8daeeba128c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded white points from CSV: 570 entries\n",
            "Common files: 84\n",
            "Dataset created: 84 images, 84 histograms\n",
            "Train samples: 67, Val samples: 17\n",
            "Successfully created data loaders!\n",
            "Train batches: 9\n",
            "Val batches: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images shape: torch.Size([8, 3, 512, 512])\n",
            "Histograms shape: torch.Size([8, 1, 128, 128])\n",
            "White points shape: torch.Size([8, 3])\n",
            "White points range: 0.500 - 0.500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "class Dist2HistLoss(nn.Module):\n",
        "    \"\"\"–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∞—è –º–µ—Ç—Ä–∏–∫–µ Dist2Hist\"\"\"\n",
        "\n",
        "    def __init__(self, alpha=0.6, beta=0.3, gamma=0.1, eps=1e-7):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            alpha: –≤–µ—Å —É–≥–ª–æ–≤–æ–π –æ—à–∏–±–∫–∏ (–æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç Dist2Hist)\n",
        "            beta: –≤–µ—Å —Ö—Ä–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è\n",
        "            gamma: –≤–µ—Å MSE –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏\n",
        "            eps: –º–∞–ª–µ–Ω—å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —á–∏—Å–ª–µ–Ω–Ω–æ–π —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏\n",
        "        \"\"\"\n",
        "        super(Dist2HistLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.gamma = gamma\n",
        "        self.eps = eps\n",
        "\n",
        "    def angular_loss(self, pred, target):\n",
        "        \"\"\"–£–≥–ª–æ–≤–∞—è –æ—à–∏–±–∫–∞ –º–µ–∂–¥—É –≤–µ–∫—Ç–æ—Ä–∞–º–∏\"\"\"\n",
        "        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ–∫—Ç–æ—Ä—ã\n",
        "        pred_norm = pred / (torch.norm(pred, dim=1, keepdim=True) + self.eps)\n",
        "        target_norm = target / (torch.norm(target, dim=1, keepdim=True) + self.eps)\n",
        "\n",
        "        # –ö–æ—Å–∏–Ω—É—Å–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å\n",
        "        cosine_sim = torch.sum(pred_norm * target_norm, dim=1)\n",
        "        cosine_sim = torch.clamp(cosine_sim, -1 + self.eps, 1 - self.eps)\n",
        "\n",
        "        # –£–≥–æ–ª –≤ —Ä–∞–¥–∏–∞–Ω–∞—Ö\n",
        "        angle = torch.acos(cosine_sim)\n",
        "        return torch.mean(angle)\n",
        "\n",
        "    def chromatic_loss(self, pred, target):\n",
        "        \"\"\"–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –≤ —Ö—Ä–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ\"\"\"\n",
        "        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ RGB –≤ —Ö—Ä–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã (Œ±, Œ≤)\n",
        "        pred_alpha = pred[:, 0] / (torch.sum(pred, dim=1) + self.eps)\n",
        "        pred_beta = pred[:, 1] / (torch.sum(pred, dim=1) + self.eps)\n",
        "\n",
        "        target_alpha = target[:, 0] / (torch.sum(target, dim=1) + self.eps)\n",
        "        target_beta = target[:, 1] / (torch.sum(target, dim=1) + self.eps)\n",
        "\n",
        "        # –ï–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –≤ —Ö—Ä–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ\n",
        "        alpha_diff = pred_alpha - target_alpha\n",
        "        beta_diff = pred_beta - target_beta\n",
        "        chroma_dist = torch.sqrt(alpha_diff**2 + beta_diff**2 + self.eps)\n",
        "\n",
        "        return torch.mean(chroma_dist)\n",
        "\n",
        "    def mse_loss(self, pred, target):\n",
        "        \"\"\"MSE –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è\"\"\"\n",
        "        return nn.MSELoss()(pred, target)\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        \"\"\"\n",
        "        –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –æ–±—â–µ–π –ø–æ—Ç–µ—Ä–∏\n",
        "\n",
        "        Args:\n",
        "            pred: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ —Ç–æ—á–∫–∏ –±–µ–ª–æ–≥–æ [batch_size, 3] –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [0, 1]\n",
        "            target: –∏—Å—Ç–∏–Ω–Ω—ã–µ —Ç–æ—á–∫–∏ –±–µ–ª–æ–≥–æ [batch_size, 3] –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [0, 1]\n",
        "\n",
        "        Returns:\n",
        "            –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–æ—Ç–µ—Ä—è, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∞—è –º–µ—Ç—Ä–∏–∫–µ Dist2Hist\n",
        "        \"\"\"\n",
        "        angular = self.angular_loss(pred, target)\n",
        "        chroma = self.chromatic_loss(pred, target)\n",
        "        mse = self.mse_loss(pred, target)\n",
        "\n",
        "        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Å –≤–µ—Å–∞–º–∏, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º–∏ –º–µ—Ç—Ä–∏–∫–µ Dist2Hist\n",
        "        total_loss = (self.alpha * angular +\n",
        "                     self.beta * chroma +\n",
        "                     self.gamma * mse)\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "class WhiteBalanceModel(nn.Module):\n",
        "    \"\"\"–ú–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ç–æ—á–∫–∏ –±–µ–ª–æ–≥–æ\"\"\"\n",
        "\n",
        "    def __init__(self, pretrained=False):\n",
        "        super(WhiteBalanceModel, self).__init__()\n",
        "\n",
        "        # –ò—Å–ø–æ–ª—å–∑—É–µ–º EfficientNet –∫–∞–∫ —ç–Ω–∫–æ–¥–µ—Ä\n",
        "        if pretrained:\n",
        "            from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
        "            self.backbone = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "        else:\n",
        "            from torchvision.models import efficientnet_b0\n",
        "            self.backbone = efficientnet_b0(weights=None)\n",
        "\n",
        "        # –ó–∞–º–µ–Ω—è–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–∞ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—É—é –≥–æ–ª–æ–≤—É\n",
        "        in_features = self.backbone.classifier[1].in_features\n",
        "\n",
        "        self.backbone.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.3),\n",
        "            nn.Linear(in_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 3),  # 3 –≤—ã—Ö–æ–¥–∞ –¥–ª—è RGB\n",
        "            nn.Sigmoid()  # –í—ã—Ö–æ–¥ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [0, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "def setup_device():\n",
        "    \"\"\"–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (GPU/CPU)\"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    return device\n",
        "\n",
        "def train_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    \"\"\"–û–¥–Ω–∞ —ç–ø–æ—Ö–∞ –æ–±—É—á–µ–Ω–∏—è\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch} Training\")\n",
        "\n",
        "    for batch_idx, (images, _, white_points) in enumerate(progress_bar):\n",
        "        images = images.to(device)\n",
        "        white_points = white_points.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, white_points)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ progress bar\n",
        "        progress_bar.set_postfix({\n",
        "            'Loss': f'{loss.item():.6f}',\n",
        "            'Avg Loss': f'{total_loss/(batch_idx+1):.6f}'\n",
        "        })\n",
        "\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "def validate_epoch(model, val_loader, criterion, device, epoch):\n",
        "    \"\"\"–í–∞–ª–∏–¥–∞—Ü–∏—è\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    progress_bar = tqdm(val_loader, desc=f\"Epoch {epoch} Validation\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, _, white_points) in enumerate(progress_bar):\n",
        "            images = images.to(device)\n",
        "            white_points = white_points.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, white_points)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            progress_bar.set_postfix({\n",
        "                'Val Loss': f'{loss.item():.6f}',\n",
        "                'Avg Val Loss': f'{total_loss/(batch_idx+1):.6f}'\n",
        "            })\n",
        "\n",
        "    return total_loss / len(val_loader)\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, loss, path):\n",
        "    \"\"\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∞\"\"\"\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss,\n",
        "        'timestamp': datetime.now().isoformat()\n",
        "    }\n",
        "    torch.save(checkpoint, path)\n",
        "    print(f\"Checkpoint saved: {path}\")\n",
        "\n",
        "def load_checkpoint(model, optimizer, checkpoint_path, device):\n",
        "    \"\"\"–ó–∞–≥—Ä—É–∑–∫–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–∞\"\"\"\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        print(f\"Checkpoint loaded from epoch {checkpoint['epoch']}\")\n",
        "        return checkpoint['epoch'], checkpoint['loss']\n",
        "    return 0, float('inf')\n",
        "\n",
        "def create_dummy_dataloaders(batch_size=8, img_size=224, num_samples=100):\n",
        "    \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ dummy dataloaders –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\"\"\"\n",
        "    from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "    # –°–æ–∑–¥–∞–µ–º dummy –¥–∞–Ω–Ω—ã–µ\n",
        "    dummy_images = torch.randn(num_samples, 3, img_size, img_size)\n",
        "    dummy_hists = torch.randn(num_samples, 1, 128, 128)  # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã\n",
        "    dummy_white_points = torch.rand(num_samples, 3)  # –¢–æ—á–∫–∏ –±–µ–ª–æ–≥–æ –≤ [0, 1]\n",
        "\n",
        "    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val\n",
        "    split = int(0.8 * num_samples)\n",
        "\n",
        "    train_dataset = TensorDataset(dummy_images[:split], dummy_hists[:split], dummy_white_points[:split])\n",
        "    val_dataset = TensorDataset(dummy_images[split:], dummy_hists[split:], dummy_white_points[split:])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    print(f\"Dummy data: {num_samples} samples\")\n",
        "    return train_loader, val_loader\n",
        "\n",
        "def main():\n",
        "    \"\"\"–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è\"\"\"\n",
        "    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è\n",
        "    config = {\n",
        "        'batch_size': 1,\n",
        "        'learning_rate': 1e-4,\n",
        "        'num_epochs': 33,\n",
        "        'val_size': 0.2,\n",
        "        'weight_decay': 1e-5,\n",
        "        'pretrained': True,\n",
        "        'checkpoint_path': 'best_model.pth',\n",
        "        'results_dir': 'results',\n",
        "        'img_size': 224\n",
        "    }\n",
        "\n",
        "    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "    os.makedirs(config['results_dir'], exist_ok=True)\n",
        "\n",
        "    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏\n",
        "    with open(f\"{config['results_dir']}/config.json\", 'w') as f:\n",
        "        json.dump(config, f, indent=4)\n",
        "\n",
        "    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞\n",
        "    device = setup_device()\n",
        "\n",
        "    # –°–æ–∑–¥–∞–Ω–∏–µ DataLoaders\n",
        "    print(\"Creating data loaders...\")\n",
        "    try:\n",
        "        # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à—É —Ñ—É–Ω–∫—Ü–∏—é —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
        "\n",
        "\n",
        "        train_loader, val_loader = create_data_loaders(\n",
        "            images_dir=\"/content/train_imgs2\",\n",
        "            histograms_dir=\"/content/train_histograms\",\n",
        "            csv_path=\"/content/train.csv\",\n",
        "            batch_size=config['batch_size'],\n",
        "            val_size=config['val_size'],\n",
        "            img_size=config['img_size']\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating data loaders: {e}\")\n",
        "        print(\"Using dummy data for testing...\")\n",
        "        train_loader, val_loader = create_dummy_dataloaders(\n",
        "            batch_size=config['batch_size'],\n",
        "            img_size=config['img_size']\n",
        "        )\n",
        "\n",
        "    print(f\"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")\n",
        "\n",
        "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\n",
        "    print(\"Initializing model...\")\n",
        "    model = WhiteBalanceModel(pretrained=config['pretrained']).to(device)\n",
        "\n",
        "    # –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å - –û–°–ù–û–í–ù–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï\n",
        "    criterion = Dist2HistLoss(alpha=0.6, beta=0.3, gamma=0.1)\n",
        "\n",
        "    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä\n",
        "    optimizer = optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=config['learning_rate'],\n",
        "        weight_decay=config['weight_decay']\n",
        "    )\n",
        "\n",
        "    # Scheduler\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=5\n",
        "    )\n",
        "\n",
        "    # –ó–∞–≥—Ä—É–∑–∫–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç\n",
        "    start_epoch, best_loss = load_checkpoint(\n",
        "        model, optimizer, config['checkpoint_path'], device\n",
        "    )\n",
        "\n",
        "    # –û–±—É—á–µ–Ω–∏–µ\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    learning_rates = []\n",
        "\n",
        "    print(\"Starting training with Dist2Hist loss...\")\n",
        "    for epoch in range(start_epoch, config['num_epochs']):\n",
        "        print(f\"\\nEpoch {epoch+1}/{config['num_epochs']}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        # –û–±—É—á–µ–Ω–∏–µ\n",
        "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device, epoch+1)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # –í–∞–ª–∏–¥–∞—Ü–∏—è\n",
        "        val_loss = validate_epoch(model, val_loader, criterion, device, epoch+1)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ scheduler\n",
        "        scheduler.step(val_loss)\n",
        "        learning_rates.append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            save_checkpoint(\n",
        "                model, optimizer, epoch, val_loss,\n",
        "                f\"{config['results_dir']}/{config['checkpoint_path']}\"\n",
        "            )\n",
        "\n",
        "        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è\n",
        "        history = {\n",
        "            'train_losses': train_losses,\n",
        "            'val_losses': val_losses,\n",
        "            'learning_rates': learning_rates,\n",
        "            'best_val_loss': best_loss\n",
        "        }\n",
        "\n",
        "        with open(f\"{config['results_dir']}/training_history.json\", 'w') as f:\n",
        "            json.dump(history, f, indent=4)\n",
        "\n",
        "        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞\n",
        "        if epoch % 5 == 0 or epoch == config['num_epochs'] - 1:\n",
        "            plt.figure(figsize=(15, 5))\n",
        "\n",
        "            plt.subplot(1, 3, 1)\n",
        "            plt.plot(train_losses, label='Train Loss', marker='o')\n",
        "            plt.plot(val_losses, label='Validation Loss', marker='s')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.title('Training Progress')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "\n",
        "            plt.subplot(1, 3, 2)\n",
        "            plt.plot(learning_rates, label='Learning Rate', marker='^', color='red')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel('Learning Rate')\n",
        "            plt.title('Learning Rate Schedule')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            plt.yscale('log')\n",
        "\n",
        "            plt.subplot(1, 3, 3)\n",
        "            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø–æ—Ç–µ—Ä—å\n",
        "            plt.bar(['Angular', 'Chromatic', 'MSE'],\n",
        "                   [criterion.alpha, criterion.beta, criterion.gamma],\n",
        "                   color=['blue', 'green', 'orange'])\n",
        "            plt.title('Loss Components Weights')\n",
        "            plt.ylabel('Weight')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f\"{config['results_dir']}/training_progress_epoch_{epoch+1}.png\")\n",
        "            plt.close()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}, LR = {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "    print(\"Training completed!\")\n",
        "    print(f\"Best validation loss: {best_loss:.6f}\")\n",
        "\n",
        "    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
        "    torch.save(model.state_dict(), f\"{config['results_dir']}/final_model.pth\")\n",
        "    print(f\"Final model saved to {config['results_dir']}/final_model.pth\")\n",
        "\n",
        "    return model, train_losses, val_losses\n",
        "\n",
        "# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É—Ç–∏–ª–∏—Ç—ã\n",
        "def test_loss_function():\n",
        "    \"\"\"–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å\"\"\"\n",
        "    criterion = Dist2HistLoss()\n",
        "\n",
        "    # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
        "    batch_size = 4\n",
        "    pred = torch.rand(batch_size, 3)  # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ [0, 1]\n",
        "    target = torch.rand(batch_size, 3)  # –¶–µ–ª–∏ –≤ [0, 1]\n",
        "\n",
        "    loss = criterion(pred, target)\n",
        "    print(f\"Test loss: {loss.item():.6f}\")\n",
        "\n",
        "    # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø–æ—Ç–µ—Ä—å\n",
        "    angular = criterion.angular_loss(pred, target)\n",
        "    chroma = criterion.chromatic_loss(pred, target)\n",
        "    mse = criterion.mse_loss(pred, target)\n",
        "\n",
        "    print(f\"Angular: {angular.item():.6f}\")\n",
        "    print(f\"Chromatic: {chroma.item():.6f}\")\n",
        "    print(f\"MSE: {mse.item():.6f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å\n",
        "    print(\"Testing loss function...\")\n",
        "    test_loss_function()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    # –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è\n",
        "    model, train_losses, val_losses = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JeWXgY-NHRet",
        "outputId": "57df87f1-c947-4168-f2ba-de9037a4c647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing loss function...\n",
            "Test loss: 0.550855\n",
            "Angular: 0.711987\n",
            "Chromatic: 0.345134\n",
            "MSE: 0.201232\n",
            "\n",
            "============================================================\n",
            "Using device: cpu\n",
            "Creating data loaders...\n",
            "Loaded white points from CSV: 570 entries\n",
            "Common files: 84\n",
            "Dataset created: 84 images, 84 histograms\n",
            "Train samples: 67, Val samples: 17\n",
            "Train batches: 67, Val batches: 17\n",
            "Initializing model...\n",
            "Starting training with Dist2Hist loss...\n",
            "\n",
            "Epoch 1/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1 Training:   0%|          | 0/67 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "Epoch 1 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:22<00:00,  3.02it/s, Loss=0.001672, Avg Loss=0.003866]\n",
            "Epoch 1 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:01<00:00,  9.64it/s, Val Loss=0.025495, Avg Val Loss=0.010755]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: results/best_model.pth\n",
            "Epoch 1: Train Loss = 0.003866, Val Loss = 0.010755, LR = 1.00e-04\n",
            "\n",
            "Epoch 2/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:22<00:00,  2.99it/s, Loss=0.002720, Avg Loss=0.003218]\n",
            "Epoch 2 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:01<00:00, 10.07it/s, Val Loss=0.006048, Avg Val Loss=0.005724]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: results/best_model.pth\n",
            "Epoch 2: Train Loss = 0.003218, Val Loss = 0.005724, LR = 1.00e-04\n",
            "\n",
            "Epoch 3/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:22<00:00,  3.04it/s, Loss=0.001049, Avg Loss=0.002210]\n",
            "Epoch 3 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:01<00:00, 10.03it/s, Val Loss=0.006263, Avg Val Loss=0.005767]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss = 0.002210, Val Loss = 0.005767, LR = 1.00e-04\n",
            "\n",
            "Epoch 4/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:21<00:00,  3.05it/s, Loss=0.000611, Avg Loss=0.001804]\n",
            "Epoch 4 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:01<00:00,  9.31it/s, Val Loss=0.005970, Avg Val Loss=0.005604]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: results/best_model.pth\n",
            "Epoch 4: Train Loss = 0.001804, Val Loss = 0.005604, LR = 1.00e-04\n",
            "\n",
            "Epoch 5/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:21<00:00,  3.14it/s, Loss=0.002091, Avg Loss=0.001616]\n",
            "Epoch 5 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:02<00:00,  6.25it/s, Val Loss=0.003224, Avg Val Loss=0.005333]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: results/best_model.pth\n",
            "Epoch 5: Train Loss = 0.001616, Val Loss = 0.005333, LR = 1.00e-04\n",
            "\n",
            "Epoch 6/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:21<00:00,  3.15it/s, Loss=0.000569, Avg Loss=0.001282]\n",
            "Epoch 6 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:01<00:00,  9.82it/s, Val Loss=0.000667, Avg Val Loss=0.003719]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: results/best_model.pth\n",
            "Epoch 6: Train Loss = 0.001282, Val Loss = 0.003719, LR = 1.00e-04\n",
            "\n",
            "Epoch 7/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:22<00:00,  2.97it/s, Loss=0.001374, Avg Loss=0.001093]\n",
            "Epoch 7 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:01<00:00,  9.62it/s, Val Loss=0.001377, Avg Val Loss=0.003056]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: results/best_model.pth\n",
            "Epoch 7: Train Loss = 0.001093, Val Loss = 0.003056, LR = 1.00e-04\n",
            "\n",
            "Epoch 8/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:22<00:00,  2.95it/s, Loss=0.000668, Avg Loss=0.001147]\n",
            "Epoch 8 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:01<00:00,  9.65it/s, Val Loss=0.003698, Avg Val Loss=0.002809]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: results/best_model.pth\n",
            "Epoch 8: Train Loss = 0.001147, Val Loss = 0.002809, LR = 1.00e-04\n",
            "\n",
            "Epoch 9/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:22<00:00,  2.94it/s, Loss=0.000821, Avg Loss=0.001031]\n",
            "Epoch 9 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:01<00:00,  9.64it/s, Val Loss=0.001262, Avg Val Loss=0.002690]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: results/best_model.pth\n",
            "Epoch 9: Train Loss = 0.001031, Val Loss = 0.002690, LR = 1.00e-04\n",
            "\n",
            "Epoch 10/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:25<00:00,  2.65it/s, Loss=0.000795, Avg Loss=0.000936]\n",
            "Epoch 10 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:01<00:00,  9.42it/s, Val Loss=0.001244, Avg Val Loss=0.002800]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train Loss = 0.000936, Val Loss = 0.002800, LR = 1.00e-04\n",
            "\n",
            "Epoch 11/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:22<00:00,  2.92it/s, Loss=0.000515, Avg Loss=0.000906]\n",
            "Epoch 11 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:01<00:00,  9.61it/s, Val Loss=0.000915, Avg Val Loss=0.001725]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: results/best_model.pth\n",
            "Epoch 11: Train Loss = 0.000906, Val Loss = 0.001725, LR = 1.00e-04\n",
            "\n",
            "Epoch 12/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:22<00:00,  2.95it/s, Loss=0.000832, Avg Loss=0.000785]\n",
            "Epoch 12 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:01<00:00,  9.59it/s, Val Loss=0.002603, Avg Val Loss=0.001811]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: Train Loss = 0.000785, Val Loss = 0.001811, LR = 1.00e-04\n",
            "\n",
            "Epoch 13/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:22<00:00,  2.99it/s, Loss=0.000611, Avg Loss=0.000742]\n",
            "Epoch 13 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:02<00:00,  7.54it/s, Val Loss=0.003691, Avg Val Loss=0.002326]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Train Loss = 0.000742, Val Loss = 0.002326, LR = 1.00e-04\n",
            "\n",
            "Epoch 14/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:21<00:00,  3.09it/s, Loss=0.000704, Avg Loss=0.000704]\n",
            "Epoch 14 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:02<00:00,  6.79it/s, Val Loss=0.008058, Avg Val Loss=0.002152]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Train Loss = 0.000704, Val Loss = 0.002152, LR = 1.00e-04\n",
            "\n",
            "Epoch 15/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:22<00:00,  3.00it/s, Loss=0.000701, Avg Loss=0.000718]\n",
            "Epoch 15 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:01<00:00,  9.61it/s, Val Loss=0.001208, Avg Val Loss=0.001826]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Train Loss = 0.000718, Val Loss = 0.001826, LR = 1.00e-04\n",
            "\n",
            "Epoch 16/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:22<00:00,  2.94it/s, Loss=0.000510, Avg Loss=0.000698]\n",
            "Epoch 16 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:01<00:00,  9.76it/s, Val Loss=0.003908, Avg Val Loss=0.001812]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: Train Loss = 0.000698, Val Loss = 0.001812, LR = 1.00e-04\n",
            "\n",
            "Epoch 17/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:22<00:00,  2.93it/s, Loss=0.000675, Avg Loss=0.000641]\n",
            "Epoch 17 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:01<00:00,  9.79it/s, Val Loss=0.004914, Avg Val Loss=0.001272]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: results/best_model.pth\n",
            "Epoch 17: Train Loss = 0.000641, Val Loss = 0.001272, LR = 1.00e-04\n",
            "\n",
            "Epoch 18/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:22<00:00,  2.95it/s, Loss=0.000558, Avg Loss=0.000636]\n",
            "Epoch 18 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:01<00:00,  9.63it/s, Val Loss=0.004085, Avg Val Loss=0.001756]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: Train Loss = 0.000636, Val Loss = 0.001756, LR = 1.00e-04\n",
            "\n",
            "Epoch 19/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:22<00:00,  2.94it/s, Loss=0.000732, Avg Loss=0.000651]\n",
            "Epoch 19 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:01<00:00,  9.60it/s, Val Loss=0.005045, Avg Val Loss=0.001554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: Train Loss = 0.000651, Val Loss = 0.001554, LR = 1.00e-04\n",
            "\n",
            "Epoch 20/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:22<00:00,  3.02it/s, Loss=0.000574, Avg Loss=0.000623]\n",
            "Epoch 20 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:02<00:00,  7.59it/s, Val Loss=0.003757, Avg Val Loss=0.001651]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: Train Loss = 0.000623, Val Loss = 0.001651, LR = 1.00e-04\n",
            "\n",
            "Epoch 21/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:21<00:00,  3.09it/s, Loss=0.000657, Avg Loss=0.000615]\n",
            "Epoch 21 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:02<00:00,  7.03it/s, Val Loss=0.003861, Avg Val Loss=0.001658]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21: Train Loss = 0.000615, Val Loss = 0.001658, LR = 1.00e-04\n",
            "\n",
            "Epoch 22/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:21<00:00,  3.07it/s, Loss=0.000684, Avg Loss=0.000613]\n",
            "Epoch 22 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:01<00:00,  9.28it/s, Val Loss=0.001738, Avg Val Loss=0.001375]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22: Train Loss = 0.000613, Val Loss = 0.001375, LR = 1.00e-04\n",
            "\n",
            "Epoch 23/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23 Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 51/67 [00:18<00:05,  2.77it/s, Loss=0.000622, Avg Loss=0.000612]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-632783599.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;31m# –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-632783599.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;31m# –û–±—É—á–µ–Ω–∏–µ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-632783599.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, criterion, optimizer, device, epoch)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"final_model.pth\")"
      ],
      "metadata": {
        "id": "46o5BEupzSoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    \"\"\"–î–∞—Ç–∞—Å–µ—Ç –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\"\"\"\n",
        "\n",
        "    def __init__(self, csv_path, images_dir, img_size=224):\n",
        "        self.csv_path = Path(csv_path)\n",
        "        self.images_dir = Path(images_dir)\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # –ó–∞–≥—Ä—É–∑–∫–∞ CSV —Ñ–∞–π–ª–∞\n",
        "        self.df = pd.read_csv(self.csv_path)\n",
        "        print(f\"Loaded test CSV: {len(self.df)} samples\")\n",
        "        print(f\"Columns: {list(self.df.columns)}\")\n",
        "\n",
        "        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ (–¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–º–∏)\n",
        "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def _read_image(self, image_path):\n",
        "        \"\"\"–ß—Ç–µ–Ω–∏–µ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\"\"\"\n",
        "        try:\n",
        "            img = cv2.imread(str(image_path), cv2.IMREAD_UNCHANGED)\n",
        "            if img is None:\n",
        "                img = cv2.imread(str(image_path), cv2.IMREAD_COLOR)\n",
        "\n",
        "            if img is None:\n",
        "                raise ValueError(f\"Cannot read image: {image_path}\")\n",
        "\n",
        "            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ float –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º\n",
        "            if img.dtype == np.uint16:\n",
        "                img = img.astype(np.float32) / 65535.0\n",
        "            elif img.dtype == np.uint8:\n",
        "                img = img.astype(np.float32) / 255.0\n",
        "\n",
        "            # BGR to RGB\n",
        "            if img.shape[-1] == 3:\n",
        "                img = img[..., ::-1]\n",
        "\n",
        "            # Resize\n",
        "            if img.shape[0] != self.img_size or img.shape[1] != self.img_size:\n",
        "                img = cv2.resize(img, (self.img_size, self.img_size))\n",
        "\n",
        "            return img\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading image {image_path}: {e}\")\n",
        "            return np.ones((self.img_size, self.img_size, 3), dtype=np.float32) * 0.5\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            row = self.df.iloc[idx]\n",
        "\n",
        "            # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –ø–µ—Ä–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü)\n",
        "            image_path_str = row.iloc[0]  # –ü–µ—Ä–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—É—Ç–∏\n",
        "            if pd.isna(image_path_str):\n",
        "                image_path_str = f\"test_image_{idx:04d}.png\"\n",
        "\n",
        "            # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π –ø—É—Ç—å\n",
        "            image_path = self.images_dir / image_path_str\n",
        "\n",
        "            # –ß—Ç–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "            image = self._read_image(image_path)\n",
        "\n",
        "            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ tensor –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "            image_tensor = torch.from_numpy(image.transpose(2, 0, 1)).float()\n",
        "            image_tensor = (image_tensor - self.mean) / self.std\n",
        "\n",
        "            return image_tensor, str(image_path_str)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading sample {idx}: {e}\")\n",
        "            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º dummy –¥–∞–Ω–Ω—ã–µ\n",
        "            dummy_image = torch.randn(3, self.img_size, self.img_size)\n",
        "            return dummy_image, f\"error_{idx}.png\"\n",
        "\n",
        "class WhiteBalanceModel(nn.Module):\n",
        "    \"\"\"–ú–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ç–æ—á–∫–∏ –±–µ–ª–æ–≥–æ\"\"\"\n",
        "\n",
        "    def __init__(self, pretrained=False):\n",
        "        super(WhiteBalanceModel, self).__init__()\n",
        "\n",
        "        # –ë–∞–∑–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (–¥–æ–ª–∂–Ω–∞ —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é)\n",
        "        from torchvision.models import efficientnet_b0\n",
        "\n",
        "        if pretrained:\n",
        "            from torchvision.models import EfficientNet_B0_Weights\n",
        "            self.backbone = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "        else:\n",
        "            self.backbone = efficientnet_b0(weights=None)\n",
        "\n",
        "        # –ó–∞–º–µ–Ω—è–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä\n",
        "        in_features = self.backbone.classifier[1].in_features\n",
        "        self.backbone.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.3),\n",
        "            nn.Linear(in_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 3),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "def load_model(model_path, device, pretrained=False):\n",
        "    \"\"\"–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\"\"\"\n",
        "    print(f\"Loading model from: {model_path}\")\n",
        "\n",
        "    model = WhiteBalanceModel(pretrained=pretrained).to(device)\n",
        "\n",
        "    if os.path.exists(model_path):\n",
        "        try:\n",
        "            # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ–ª–Ω—ã–π checkpoint –∏–ª–∏ —Ç–æ–ª—å–∫–æ –≤–µ—Å–∞\n",
        "            checkpoint = torch.load(model_path, map_location=device)\n",
        "\n",
        "            if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
        "                model.load_state_dict(checkpoint['model_state_dict'])\n",
        "                print(\"Loaded from checkpoint\")\n",
        "            else:\n",
        "                model.load_state_dict(checkpoint)\n",
        "                print(\"Loaded model weights\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model: {e}\")\n",
        "            print(\"Using randomly initialized model\")\n",
        "    else:\n",
        "        print(f\"Model file not found: {model_path}\")\n",
        "        print(\"Using randomly initialized model\")\n",
        "\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def create_predictions(model, test_loader, device):\n",
        "    \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞\"\"\"\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_image_paths = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, image_paths in tqdm(test_loader, desc=\"Making predictions\"):\n",
        "            images = images.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "\n",
        "            # –î–µ–Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏–∑ [0, 1] –≤ [0, 65535]\n",
        "            predictions = outputs.cpu().numpy() * 65535.0\n",
        "\n",
        "            all_predictions.extend(predictions)\n",
        "            all_image_paths.extend(image_paths)\n",
        "\n",
        "    return all_image_paths, all_predictions\n",
        "\n",
        "def create_submission_file(image_paths, predictions, output_csv=\"submission.csv\"):\n",
        "    \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ submission —Ñ–∞–π–ª–∞ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ\"\"\"\n",
        "    print(f\"Creating submission file: {output_csv}\")\n",
        "\n",
        "    data = []\n",
        "    for img_path, pred in zip(image_paths, predictions):\n",
        "        try:\n",
        "            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –∏–º—è —Ñ–∞–π–ª–∞ (–±–µ–∑ –ø—É—Ç–∏)\n",
        "            if isinstance(img_path, str):\n",
        "                filename = Path(img_path).name\n",
        "            else:\n",
        "                filename = f\"image_{len(data):04d}.png\"\n",
        "\n",
        "            # –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω –∑–Ω–∞—á–µ–Ω–∏–π [0, 65535]\n",
        "            wp_r = float(np.clip(pred[0], 0, 65535))\n",
        "            wp_g = float(np.clip(pred[1], 0, 65535))\n",
        "            wp_b = float(np.clip(pred[2], 0, 65535))\n",
        "\n",
        "            data.append({\n",
        "                'image_path': filename,\n",
        "                'wp_r': wp_r,\n",
        "                'wp_g': wp_g,\n",
        "                'wp_b': wp_b\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_path}: {e}\")\n",
        "            # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n",
        "            data.append({\n",
        "                'image_path': f\"error_{len(data):04d}.png\",\n",
        "                'wp_r': 32768.0,\n",
        "                'wp_g': 32768.0,\n",
        "                'wp_b': 32768.0\n",
        "            })\n",
        "\n",
        "    # –°–æ–∑–¥–∞–µ–º DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º CSV\n",
        "    df.to_csv(output_csv, index=False, float_format='%.6f')\n",
        "\n",
        "    print(f\"Submission file created with {len(df)} predictions\")\n",
        "    print(\"First 5 predictions:\")\n",
        "    print(df.head())\n",
        "\n",
        "    return df\n",
        "\n",
        "def main():\n",
        "    \"\"\"–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\"\"\"\n",
        "\n",
        "    # –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º\n",
        "    TEST_CSV_PATH = \"/content/test.csv\"\n",
        "    TEST_IMAGES_DIR = \"/content/test_imgs2\"\n",
        "    MODEL_PATH = \"/content/final_model.pth\"\n",
        "    OUTPUT_CSV = \"/content/final_submission.csv\"\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"üîÑ CREATING PREDICTIONS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–æ–≤\n",
        "    print(\"üîç Checking files...\")\n",
        "    print(f\"Test CSV: {TEST_CSV_PATH} ‚Üí {'‚úÖ' if os.path.exists(TEST_CSV_PATH) else '‚ùå'}\")\n",
        "    print(f\"Test images: {TEST_IMAGES_DIR} ‚Üí {'‚úÖ' if os.path.exists(TEST_IMAGES_DIR) else '‚ùå'}\")\n",
        "    print(f\"Model: {MODEL_PATH} ‚Üí {'‚úÖ' if os.path.exists(MODEL_PATH) else '‚ùå'}\")\n",
        "\n",
        "    if not os.path.exists(TEST_CSV_PATH):\n",
        "        print(\"‚ùå Test CSV not found!\")\n",
        "        return\n",
        "\n",
        "    # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"üñ•Ô∏è  Device: {device}\")\n",
        "\n",
        "    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç\n",
        "    print(\"\\nüìÅ Creating test dataset...\")\n",
        "    try:\n",
        "        test_dataset = TestDataset(TEST_CSV_PATH, TEST_IMAGES_DIR)\n",
        "        print(f\"‚úÖ Test dataset created: {len(test_dataset)} samples\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error creating dataset: {e}\")\n",
        "        return\n",
        "\n",
        "    # DataLoader\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=8,\n",
        "        shuffle=False,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏\n",
        "    print(\"\\nü§ñ Loading model...\")\n",
        "    model = load_model(MODEL_PATH, device, pretrained=False)\n",
        "\n",
        "    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
        "    print(\"\\nüéØ Making predictions...\")\n",
        "    image_paths, predictions = create_predictions(model, test_loader, device)\n",
        "\n",
        "    # –°–æ–∑–¥–∞–Ω–∏–µ submission —Ñ–∞–π–ª–∞\n",
        "    print(\"\\nüíæ Creating submission file...\")\n",
        "    submission_df = create_submission_file(image_paths, predictions, OUTPUT_CSV)\n",
        "\n",
        "    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
        "    print(\"\\nüìä Prediction statistics:\")\n",
        "    pred_array = np.array(predictions)\n",
        "    print(f\"Total predictions: {len(predictions)}\")\n",
        "    print(f\"Value ranges:\")\n",
        "    print(f\"  R: {pred_array[:, 0].min():.1f} - {pred_array[:, 0].max():.1f}\")\n",
        "    print(f\"  G: {pred_array[:, 1].min():.1f} - {pred_array[:, 1].max():.1f}\")\n",
        "    print(f\"  B: {pred_array[:, 2].min():.1f} - {pred_array[:, 2].max():.1f}\")\n",
        "\n",
        "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –∑–Ω–∞—á–µ–Ω–∏–π\n",
        "    valid_mask = np.all((pred_array >= 0) & (pred_array <= 65535), axis=1)\n",
        "    invalid_count = np.sum(~valid_mask)\n",
        "\n",
        "    if invalid_count > 0:\n",
        "        print(f\"‚ö†Ô∏è  Warning: {invalid_count} predictions outside valid range [0, 65535]\")\n",
        "    else:\n",
        "        print(\"‚úÖ All predictions are within valid range\")\n",
        "\n",
        "    print(f\"\\nüéâ Done! Submission file saved to: {OUTPUT_CSV}\")\n",
        "\n",
        "# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è –ø—Ä–æ—Å—Ç–∞—è –≤–µ—Ä—Å–∏—è\n",
        "def quick_predict():\n",
        "    \"\"\"–ë—ã—Å—Ç—Ä–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\"\"\"\n",
        "\n",
        "    # –ü—É—Ç–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n",
        "    paths = {\n",
        "        'test_csv': '/content/test (3).csv',\n",
        "        'test_images': '/content/test_imgs',\n",
        "        'model': '/content/final_model.pth',\n",
        "        'output': '/content/submission (1).csv'\n",
        "    }\n",
        "\n",
        "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤\n",
        "    for name, path in paths.items():\n",
        "        if not os.path.exists(path) and name != 'output':\n",
        "            print(f\"‚ùå File not found: {path}\")\n",
        "            return\n",
        "\n",
        "    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å\n",
        "    main()\n",
        "\n",
        "# –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
        "def check_submission_format():\n",
        "    \"\"\"–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ–æ—Ä–º–∞—Ç submission —Ñ–∞–π–ª–∞\"\"\"\n",
        "    try:\n",
        "        # –ü—Ä–∏–º–µ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞\n",
        "        example_data = {\n",
        "            'image_path': ['test1.png', 'test2.png'],\n",
        "            'wp_r': [30000.0, 32000.0],\n",
        "            'wp_g': [31000.0, 33000.0],\n",
        "            'wp_b': [29000.0, 28000.0]\n",
        "        }\n",
        "\n",
        "        example_df = pd.DataFrame(example_data)\n",
        "        print(\"üìã Example submission format:\")\n",
        "        print(example_df)\n",
        "        print(\"\\n‚úÖ Columns should be: image_path, wp_r, wp_g, wp_b\")\n",
        "        print(\"‚úÖ Values should be in range [0, 65535]\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä —Ñ–æ—Ä–º–∞—Ç–∞\n",
        "    check_submission_format()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
        "    main()\n",
        "\n",
        "    # –ò–ª–∏ –±—ã—Å—Ç—Ä—ã–π –∑–∞–ø—É—Å–∫\n",
        "    # quick_predict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWLuljwXhl7W",
        "outputId": "b6f693b5-79d4-4a08-91c3-67a2f42e7e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìã Example submission format:\n",
            "  image_path     wp_r     wp_g     wp_b\n",
            "0  test1.png  30000.0  31000.0  29000.0\n",
            "1  test2.png  32000.0  33000.0  28000.0\n",
            "\n",
            "‚úÖ Columns should be: image_path, wp_r, wp_g, wp_b\n",
            "‚úÖ Values should be in range [0, 65535]\n",
            "\n",
            "============================================================\n",
            "============================================================\n",
            "üîÑ CREATING PREDICTIONS\n",
            "============================================================\n",
            "üîç Checking files...\n",
            "Test CSV: /content/test.csv ‚Üí ‚úÖ\n",
            "Test images: /content/test_imgs2 ‚Üí ‚ùå\n",
            "Model: /content/final_model.pth ‚Üí ‚úÖ\n",
            "üñ•Ô∏è  Device: cpu\n",
            "\n",
            "üìÅ Creating test dataset...\n",
            "Loaded test CSV: 145 samples\n",
            "Columns: ['names']\n",
            "‚úÖ Test dataset created: 145 samples\n",
            "\n",
            "ü§ñ Loading model...\n",
            "Loading model from: /content/final_model.pth\n",
            "Loaded model weights\n",
            "\n",
            "üéØ Making predictions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:   0%|          | 0/19 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0001.png: Cannot read image: /content/test_imgs2/test_imgs/0001.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0015.png: Cannot read image: /content/test_imgs2/test_imgs/0015.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0034.png: Cannot read image: /content/test_imgs2/test_imgs/0034.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0018.png: Cannot read image: /content/test_imgs2/test_imgs/0018.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0035.png: Cannot read image: /content/test_imgs2/test_imgs/0035.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0019.png: Cannot read image: /content/test_imgs2/test_imgs/0019.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0042.png: Cannot read image: /content/test_imgs2/test_imgs/0042.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0020.png: Cannot read image: /content/test_imgs2/test_imgs/0020.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0049.png: Cannot read image: /content/test_imgs2/test_imgs/0049.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0055.png: Cannot read image: /content/test_imgs2/test_imgs/0055.pngError reading image /content/test_imgs2/test_imgs/0022.png: Cannot read image: /content/test_imgs2/test_imgs/0022.png\n",
            "\n",
            "Error reading image /content/test_imgs2/test_imgs/0061.png: Cannot read image: /content/test_imgs2/test_imgs/0061.pngError reading image /content/test_imgs2/test_imgs/0027.png: Cannot read image: /content/test_imgs2/test_imgs/0027.png\n",
            "\n",
            "Error reading image /content/test_imgs2/test_imgs/0062.png: Cannot read image: /content/test_imgs2/test_imgs/0062.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0030.png: Cannot read image: /content/test_imgs2/test_imgs/0030.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0083.png: Cannot read image: /content/test_imgs2/test_imgs/0083.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0087.png: Cannot read image: /content/test_imgs2/test_imgs/0087.pngError reading image /content/test_imgs2/test_imgs/0133.png: Cannot read image: /content/test_imgs2/test_imgs/0133.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0134.png: Cannot read image: /content/test_imgs2/test_imgs/0134.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0091.png: Cannot read image: /content/test_imgs2/test_imgs/0091.png\n",
            "\n",
            "Error reading image /content/test_imgs2/test_imgs/0094.png: Cannot read image: /content/test_imgs2/test_imgs/0094.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0095.png: Cannot read image: /content/test_imgs2/test_imgs/0095.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0150.png: Cannot read image: /content/test_imgs2/test_imgs/0150.pngError reading image /content/test_imgs2/test_imgs/0100.png: Cannot read image: /content/test_imgs2/test_imgs/0100.png\n",
            "\n",
            "Error reading image /content/test_imgs2/test_imgs/0126.png: Cannot read image: /content/test_imgs2/test_imgs/0126.pngError reading image /content/test_imgs2/test_imgs/0154.png: Cannot read image: /content/test_imgs2/test_imgs/0154.png\n",
            "\n",
            "Error reading image /content/test_imgs2/test_imgs/0169.png: Cannot read image: /content/test_imgs2/test_imgs/0169.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0175.png: Cannot read image: /content/test_imgs2/test_imgs/0175.pngError reading image /content/test_imgs2/test_imgs/0127.png: Cannot read image: /content/test_imgs2/test_imgs/0127.png\n",
            "\n",
            "Error reading image /content/test_imgs2/test_imgs/0179.png: Cannot read image: /content/test_imgs2/test_imgs/0179.pngError reading image /content/test_imgs2/test_imgs/0132.png: Cannot read image: /content/test_imgs2/test_imgs/0132.png\n",
            "\n",
            "Error reading image /content/test_imgs2/test_imgs/0182.png: Cannot read image: /content/test_imgs2/test_imgs/0182.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0186.png: Cannot read image: /content/test_imgs2/test_imgs/0186.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0187.png: Cannot read image: /content/test_imgs2/test_imgs/0187.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0192.png: Cannot read image: /content/test_imgs2/test_imgs/0192.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0199.png: Cannot read image: /content/test_imgs2/test_imgs/0199.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0208.png: Cannot read image: /content/test_imgs2/test_imgs/0208.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0222.png: Cannot read image: /content/test_imgs2/test_imgs/0222.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0228.png: Cannot read image: /content/test_imgs2/test_imgs/0228.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0234.png: Cannot read image: /content/test_imgs2/test_imgs/0234.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:   5%|‚ñå         | 1/19 [00:01<00:19,  1.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0238.png: Cannot read image: /content/test_imgs2/test_imgs/0238.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0239.png: Cannot read image: /content/test_imgs2/test_imgs/0239.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0241.png: Cannot read image: /content/test_imgs2/test_imgs/0241.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0242.png: Cannot read image: /content/test_imgs2/test_imgs/0242.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0243.png: Cannot read image: /content/test_imgs2/test_imgs/0243.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0245.png: Cannot read image: /content/test_imgs2/test_imgs/0245.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0264.png: Cannot read image: /content/test_imgs2/test_imgs/0264.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0291.png: Cannot read image: /content/test_imgs2/test_imgs/0291.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  11%|‚ñà         | 2/19 [00:01<00:15,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0297.png: Cannot read image: /content/test_imgs2/test_imgs/0297.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0312.png: Cannot read image: /content/test_imgs2/test_imgs/0312.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0313.png: Cannot read image: /content/test_imgs2/test_imgs/0313.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0317.png: Cannot read image: /content/test_imgs2/test_imgs/0317.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0319.png: Cannot read image: /content/test_imgs2/test_imgs/0319.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0334.png: Cannot read image: /content/test_imgs2/test_imgs/0334.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0341.png: Cannot read image: /content/test_imgs2/test_imgs/0341.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0348.png: Cannot read image: /content/test_imgs2/test_imgs/0348.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  16%|‚ñà‚ñå        | 3/19 [00:02<00:13,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0351.png: Cannot read image: /content/test_imgs2/test_imgs/0351.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0355.png: Cannot read image: /content/test_imgs2/test_imgs/0355.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0357.png: Cannot read image: /content/test_imgs2/test_imgs/0357.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0358.png: Cannot read image: /content/test_imgs2/test_imgs/0358.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0359.png: Cannot read image: /content/test_imgs2/test_imgs/0359.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0373.png: Cannot read image: /content/test_imgs2/test_imgs/0373.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0376.png: Cannot read image: /content/test_imgs2/test_imgs/0376.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0377.png: Cannot read image: /content/test_imgs2/test_imgs/0377.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  21%|‚ñà‚ñà        | 4/19 [00:03<00:12,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0379.png: Cannot read image: /content/test_imgs2/test_imgs/0379.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0380.png: Cannot read image: /content/test_imgs2/test_imgs/0380.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0385.png: Cannot read image: /content/test_imgs2/test_imgs/0385.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0396.png: Cannot read image: /content/test_imgs2/test_imgs/0396.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0401.png: Cannot read image: /content/test_imgs2/test_imgs/0401.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0407.png: Cannot read image: /content/test_imgs2/test_imgs/0407.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0411.png: Cannot read image: /content/test_imgs2/test_imgs/0411.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0416.png: Cannot read image: /content/test_imgs2/test_imgs/0416.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  26%|‚ñà‚ñà‚ñã       | 5/19 [00:04<00:11,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0443.png: Cannot read image: /content/test_imgs2/test_imgs/0443.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0456.png: Cannot read image: /content/test_imgs2/test_imgs/0456.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0464.png: Cannot read image: /content/test_imgs2/test_imgs/0464.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0470.png: Cannot read image: /content/test_imgs2/test_imgs/0470.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0479.png: Cannot read image: /content/test_imgs2/test_imgs/0479.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0486.png: Cannot read image: /content/test_imgs2/test_imgs/0486.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0496.png: Cannot read image: /content/test_imgs2/test_imgs/0496.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0500.png: Cannot read image: /content/test_imgs2/test_imgs/0500.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 6/19 [00:04<00:09,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0513.png: Cannot read image: /content/test_imgs2/test_imgs/0513.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0528.png: Cannot read image: /content/test_imgs2/test_imgs/0528.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0534.png: Cannot read image: /content/test_imgs2/test_imgs/0534.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0558.png: Cannot read image: /content/test_imgs2/test_imgs/0558.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0570.png: Cannot read image: /content/test_imgs2/test_imgs/0570.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0574.png: Cannot read image: /content/test_imgs2/test_imgs/0574.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0589.png: Cannot read image: /content/test_imgs2/test_imgs/0589.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0592.png: Cannot read image: /content/test_imgs2/test_imgs/0592.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 7/19 [00:05<00:08,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0596.png: Cannot read image: /content/test_imgs2/test_imgs/0596.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0600.png: Cannot read image: /content/test_imgs2/test_imgs/0600.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0601.png: Cannot read image: /content/test_imgs2/test_imgs/0601.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0604.png: Cannot read image: /content/test_imgs2/test_imgs/0604.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0609.png: Cannot read image: /content/test_imgs2/test_imgs/0609.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0614.png: Cannot read image: /content/test_imgs2/test_imgs/0614.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0616.png: Cannot read image: /content/test_imgs2/test_imgs/0616.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0627.png: Cannot read image: /content/test_imgs2/test_imgs/0627.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 8/19 [00:05<00:07,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0634.png: Cannot read image: /content/test_imgs2/test_imgs/0634.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0644.png: Cannot read image: /content/test_imgs2/test_imgs/0644.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0647.png: Cannot read image: /content/test_imgs2/test_imgs/0647.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0649.png: Cannot read image: /content/test_imgs2/test_imgs/0649.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0661.png: Cannot read image: /content/test_imgs2/test_imgs/0661.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0665.png: Cannot read image: /content/test_imgs2/test_imgs/0665.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0669.png: Cannot read image: /content/test_imgs2/test_imgs/0669.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0677.png: Cannot read image: /content/test_imgs2/test_imgs/0677.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 9/19 [00:06<00:06,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0679.png: Cannot read image: /content/test_imgs2/test_imgs/0679.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0682.png: Cannot read image: /content/test_imgs2/test_imgs/0682.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0687.png: Cannot read image: /content/test_imgs2/test_imgs/0687.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0693.png: Cannot read image: /content/test_imgs2/test_imgs/0693.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0700.png: Cannot read image: /content/test_imgs2/test_imgs/0700.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0709.png: Cannot read image: /content/test_imgs2/test_imgs/0709.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0726.png: Cannot read image: /content/test_imgs2/test_imgs/0726.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0727.png: Cannot read image: /content/test_imgs2/test_imgs/0727.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 10/19 [00:07<00:05,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0752.png: Cannot read image: /content/test_imgs2/test_imgs/0752.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0757.png: Cannot read image: /content/test_imgs2/test_imgs/0757.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0760.png: Cannot read image: /content/test_imgs2/test_imgs/0760.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0763.png: Cannot read image: /content/test_imgs2/test_imgs/0763.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0768.png: Cannot read image: /content/test_imgs2/test_imgs/0768.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0770.png: Cannot read image: /content/test_imgs2/test_imgs/0770.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0774.png: Cannot read image: /content/test_imgs2/test_imgs/0774.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0778.png: Cannot read image: /content/test_imgs2/test_imgs/0778.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 11/19 [00:07<00:04,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0791.png: Cannot read image: /content/test_imgs2/test_imgs/0791.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0792.png: Cannot read image: /content/test_imgs2/test_imgs/0792.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0799.png: Cannot read image: /content/test_imgs2/test_imgs/0799.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0800.png: Cannot read image: /content/test_imgs2/test_imgs/0800.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0804.png: Cannot read image: /content/test_imgs2/test_imgs/0804.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0806.png: Cannot read image: /content/test_imgs2/test_imgs/0806.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0816.png: Cannot read image: /content/test_imgs2/test_imgs/0816.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0818.png: Cannot read image: /content/test_imgs2/test_imgs/0818.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 12/19 [00:08<00:04,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0821.png: Cannot read image: /content/test_imgs2/test_imgs/0821.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0823.png: Cannot read image: /content/test_imgs2/test_imgs/0823.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0842.png: Cannot read image: /content/test_imgs2/test_imgs/0842.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0852.png: Cannot read image: /content/test_imgs2/test_imgs/0852.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0855.png: Cannot read image: /content/test_imgs2/test_imgs/0855.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0868.png: Cannot read image: /content/test_imgs2/test_imgs/0868.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0877.png: Cannot read image: /content/test_imgs2/test_imgs/0877.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0883.png: Cannot read image: /content/test_imgs2/test_imgs/0883.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 13/19 [00:08<00:03,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0890.png: Cannot read image: /content/test_imgs2/test_imgs/0890.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0895.png: Cannot read image: /content/test_imgs2/test_imgs/0895.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0896.png: Cannot read image: /content/test_imgs2/test_imgs/0896.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0909.png: Cannot read image: /content/test_imgs2/test_imgs/0909.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0912.png: Cannot read image: /content/test_imgs2/test_imgs/0912.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0917.png: Cannot read image: /content/test_imgs2/test_imgs/0917.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0924.png: Cannot read image: /content/test_imgs2/test_imgs/0924.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0925.png: Cannot read image: /content/test_imgs2/test_imgs/0925.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 14/19 [00:09<00:02,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0926.png: Cannot read image: /content/test_imgs2/test_imgs/0926.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:11<00:00,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üíæ Creating submission file...\n",
            "Creating submission file: /content/final_submission.csv\n",
            "Submission file created with 145 predictions\n",
            "First 5 predictions:\n",
            "  image_path     wp_r  wp_g  wp_b\n",
            "0   0001.png  65535.0   0.0   0.0\n",
            "1   0015.png  65535.0   0.0   0.0\n",
            "2   0018.png  65535.0   0.0   0.0\n",
            "3   0019.png  65535.0   0.0   0.0\n",
            "4   0020.png  65535.0   0.0   0.0\n",
            "\n",
            "üìä Prediction statistics:\n",
            "Total predictions: 145\n",
            "Value ranges:\n",
            "  R: 65535.0 - 65535.0\n",
            "  G: 0.0 - 0.0\n",
            "  B: 0.0 - 0.0\n",
            "‚úÖ All predictions are within valid range\n",
            "\n",
            "üéâ Done! Submission file saved to: /content/final_submission.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def merge_submission_files(submission_path, source_path, output_path):\n",
        "    \"\"\"\n",
        "    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ: –±–µ—Ä–µ—Ç –ø–µ—Ä–≤—É—é –∫–æ–ª–æ–Ω–∫—É –∏–∑ submission —Ñ–∞–π–ª–∞\n",
        "    –∏ –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ç—Ä–∏ –∫–æ–ª–æ–Ω–∫–∏ –∏–∑ source —Ñ–∞–π–ª–∞\n",
        "\n",
        "    Args:\n",
        "        submission_path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É submission.csv (–æ—Ç–∫—É–¥–∞ –±–µ—Ä–µ–º image_path)\n",
        "        source_path: –ø—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É (–æ—Ç–∫—É–¥–∞ –±–µ—Ä–µ–º wp_r, wp_g, wp_b)\n",
        "        output_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"üîç Reading files...\")\n",
        "\n",
        "    try:\n",
        "        # –ß–∏—Ç–∞–µ–º submission —Ñ–∞–π–ª\n",
        "        submission_df = pd.read_csv(submission_path)\n",
        "        print(f\"‚úÖ Submission file loaded: {len(submission_df)} rows\")\n",
        "        print(f\"   Columns: {list(submission_df.columns)}\")\n",
        "\n",
        "        # –ß–∏—Ç–∞–µ–º source —Ñ–∞–π–ª\n",
        "        source_df = pd.read_csv(source_path)\n",
        "        print(f\"‚úÖ Source file loaded: {len(source_df)} rows\")\n",
        "        print(f\"   Columns: {list(source_df.columns)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error reading files: {e}\")\n",
        "        return None\n",
        "\n",
        "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª—ã –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫\n",
        "    if len(submission_df) != len(source_df):\n",
        "        print(f\"‚ö†Ô∏è  Warning: Different number of rows!\")\n",
        "        print(f\"   Submission: {len(submission_df)} rows\")\n",
        "        print(f\"   Source: {len(source_df)} rows\")\n",
        "\n",
        "        # –ë–µ—Ä–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫\n",
        "        min_rows = min(len(submission_df), len(source_df))\n",
        "        submission_df = submission_df.head(min_rows)\n",
        "        source_df = source_df.head(min_rows)\n",
        "        print(f\"   Using first {min_rows} rows from each file\")\n",
        "\n",
        "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
        "    submission_cols = submission_df.columns\n",
        "    source_cols = source_df.columns\n",
        "\n",
        "    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –ø—É—Ç—è–º–∏ –∏–∑ submission —Ñ–∞–π–ª–∞\n",
        "    if 'image_path' in submission_cols:\n",
        "        image_path_col = 'image_path'\n",
        "    else:\n",
        "        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –∫–æ–ª–æ–Ω–∫—É\n",
        "        image_path_col = submission_cols[0]\n",
        "        print(f\"‚ÑπÔ∏è  Using first column as image_path: {image_path_col}\")\n",
        "\n",
        "    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è white balance –∏–∑ source —Ñ–∞–π–ª–∞\n",
        "    wp_cols = []\n",
        "    for col in ['wp_r', 'wp_g', 'wp_b']:\n",
        "        if col in source_cols:\n",
        "            wp_cols.append(col)\n",
        "        else:\n",
        "            # –ò—â–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è\n",
        "            for source_col in source_cols:\n",
        "                if col in source_col.lower() or 'white' in source_col.lower():\n",
        "                    wp_cols.append(source_col)\n",
        "                    print(f\"‚ÑπÔ∏è  Using {source_col} as {col}\")\n",
        "                    break\n",
        "            else:\n",
        "                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ —Ç—Ä–∏ –∫–æ–ª–æ–Ω–∫–∏ –ø–æ—Å–ª–µ image_path\n",
        "                if len(source_cols) >= 4:\n",
        "                    wp_cols.extend(source_cols[1:4])\n",
        "                else:\n",
        "                    wp_cols.extend(source_cols[:3])\n",
        "                print(f\"‚ÑπÔ∏è  Using columns {wp_cols} for white balance values\")\n",
        "                break\n",
        "\n",
        "    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 3 –∫–æ–ª–æ–Ω–æ–∫\n",
        "    wp_cols = wp_cols[:3]\n",
        "\n",
        "    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π DataFrame\n",
        "    print(\"\\nüîÑ Merging data...\")\n",
        "\n",
        "    try:\n",
        "        # –ë–µ—Ä–µ–º image_path –∏–∑ submission —Ñ–∞–π–ª–∞\n",
        "        result_df = pd.DataFrame()\n",
        "        result_df['image_path'] = submission_df[image_path_col]\n",
        "\n",
        "        # –ë–µ—Ä–µ–º white balance –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ source —Ñ–∞–π–ª–∞\n",
        "        for i, col in enumerate(wp_cols[:3]):  # –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º—É–º 3 –∫–æ–ª–æ–Ω–∫–∏\n",
        "            if i == 0:\n",
        "                result_df['wp_r'] = source_df[col]\n",
        "            elif i == 1:\n",
        "                result_df['wp_g'] = source_df[col]\n",
        "            elif i == 2:\n",
        "                result_df['wp_b'] = source_df[col]\n",
        "\n",
        "        # –ï—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∏–ª–æ –∫–æ–ª–æ–Ω–æ–∫, –∑–∞–ø–æ–ª–Ω—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n",
        "        if len(wp_cols) < 3:\n",
        "            print(f\"‚ö†Ô∏è  Only {len(wp_cols)} white balance columns found\")\n",
        "            if 'wp_r' not in result_df.columns:\n",
        "                result_df['wp_r'] = 32768.0\n",
        "            if 'wp_g' not in result_df.columns:\n",
        "                result_df['wp_g'] = 32768.0\n",
        "            if 'wp_b' not in result_df.columns:\n",
        "                result_df['wp_b'] = 32768.0\n",
        "\n",
        "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
        "        result_df.to_csv(output_path, index=False, float_format='%.6f')\n",
        "\n",
        "        print(f\"‚úÖ Merged file saved: {output_path}\")\n",
        "        print(f\"üìä Result shape: {result_df.shape}\")\n",
        "        print(f\"üìã Columns: {list(result_df.columns)}\")\n",
        "        print(\"\\nüìÑ First 5 rows:\")\n",
        "        print(result_df.head())\n",
        "\n",
        "        return result_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error merging files: {e}\")\n",
        "        return None\n",
        "\n",
        "def create_manual_merge(submission_path, source_path, output_path):\n",
        "    \"\"\"\n",
        "    –†—É—á–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –≤—ã–±–æ—Ä–æ–º –∫–æ–ª–æ–Ω–æ–∫\n",
        "    \"\"\"\n",
        "    print(\"üìù Manual merge mode\")\n",
        "\n",
        "    # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª—ã\n",
        "    submission_df = pd.read_csv(submission_path)\n",
        "    source_df = pd.read_csv(source_path)\n",
        "\n",
        "    print(f\"Submission file columns: {list(submission_df.columns)}\")\n",
        "    print(f\"Source file columns: {list(source_df.columns)}\")\n",
        "\n",
        "    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π DataFrame\n",
        "    result_df = pd.DataFrame()\n",
        "\n",
        "    # –í—ã–±–∏—Ä–∞–µ–º –∫–æ–ª–æ–Ω–∫—É –¥–ª—è image_path\n",
        "    image_col = input(\"Enter column name for image_path from submission file: \").strip()\n",
        "    if image_col not in submission_df.columns:\n",
        "        print(f\"Column '{image_col}' not found, using first column\")\n",
        "        image_col = submission_df.columns[0]\n",
        "\n",
        "    result_df['image_path'] = submission_df[image_col]\n",
        "\n",
        "    # –í—ã–±–∏—Ä–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è white balance\n",
        "    wp_mapping = {}\n",
        "    for wp_col in ['wp_r', 'wp_g', 'wp_b']:\n",
        "        col_name = input(f\"Enter column name for {wp_col} from source file: \").strip()\n",
        "        if col_name in source_df.columns:\n",
        "            result_df[wp_col] = source_df[col_name]\n",
        "            wp_mapping[wp_col] = col_name\n",
        "        else:\n",
        "            print(f\"Column '{col_name}' not found, using default value 32768.0\")\n",
        "            result_df[wp_col] = 32768.0\n",
        "\n",
        "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º\n",
        "    result_df.to_csv(output_path, index=False, float_format='%.6f')\n",
        "    print(f\"‚úÖ Manual merge saved to: {output_path}\")\n",
        "\n",
        "    return result_df\n",
        "\n",
        "def quick_merge():\n",
        "    \"\"\"\n",
        "    –ë—ã—Å—Ç—Ä–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º–∏ –ø—É—Ç—è–º–∏\n",
        "    \"\"\"\n",
        "    submission_file = \"/content/submission.csv\"\n",
        "    source_file = \"/content/submission.csv\"  # –∏–ª–∏ –≤–∞—à —Ñ–∞–π–ª —Å white balance –∑–Ω–∞—á–µ–Ω–∏—è–º–∏\n",
        "    output_file = \"/content/merged_submission.csv\"\n",
        "\n",
        "    print(\"üöÄ Quick merge with default paths:\")\n",
        "    print(f\"Submission: {submission_file}\")\n",
        "    print(f\"Source: {source_file}\")\n",
        "    print(f\"Output: {output_file}\")\n",
        "\n",
        "    return merge_submission_files(submission_file, source_file, output_file)\n",
        "\n",
        "# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É—Ç–∏–ª–∏—Ç—ã\n",
        "def check_file_info(file_path):\n",
        "    \"\"\"–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∞–π–ª–µ\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        print(f\"üìÅ File: {file_path}\")\n",
        "        print(f\"üìä Shape: {df.shape}\")\n",
        "        print(f\"üìã Columns: {list(df.columns)}\")\n",
        "        print(f\"üî¢ Dtypes:\\n{df.dtypes}\")\n",
        "        print(\"\\nüìÑ First 3 rows:\")\n",
        "        print(df.head(3))\n",
        "        print(\"\\nüìÑ Last 3 rows:\")\n",
        "        print(df.tail(3))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error reading {file_path}: {e}\")\n",
        "\n",
        "def compare_files(file1_path, file2_path):\n",
        "    \"\"\"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö —Ñ–∞–π–ª–æ–≤\"\"\"\n",
        "    df1 = pd.read_csv(file1_path)\n",
        "    df2 = pd.read_csv(file2_path)\n",
        "\n",
        "    print(\"üìä File Comparison:\")\n",
        "    print(f\"File 1: {file1_path} - {df1.shape}\")\n",
        "    print(f\"File 2: {file2_path} - {df2.shape}\")\n",
        "\n",
        "    print(\"\\nüìã Columns comparison:\")\n",
        "    print(f\"File 1 columns: {list(df1.columns)}\")\n",
        "    print(f\"File 2 columns: {list(df2.columns)}\")\n",
        "\n",
        "    common_cols = set(df1.columns) & set(df2.columns)\n",
        "    print(f\"Common columns: {common_cols}\")\n",
        "\n",
        "# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è\n",
        "def main():\n",
        "    \"\"\"–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≤ Colab\"\"\"\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"üìä SUBISSION FILE MERGER\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø—É—Ç–∏ –¥–ª—è Colab\n",
        "    files_to_check = [\n",
        "        \"/content/submission.csv\",\n",
        "        \"/content/you1.csv\",\n",
        "        \"/content/train.csv\"\n",
        "    ]\n",
        "\n",
        "    print(\"üîç Checking available files:\")\n",
        "    for file_path in files_to_check:\n",
        "        exists = Path(file_path).exists()\n",
        "        status = \"‚úÖ\" if exists else \"‚ùå\"\n",
        "        print(f\"{status} {file_path}\")\n",
        "\n",
        "    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ source —Ñ–∞–π–ª–∞\n",
        "    source_candidates = [\n",
        "        \"/content/you1.csv\",\n",
        "        \"/content/train.csv\",\n",
        "        \"/content/test.csv\",\n",
        "        \"/content/data.csv\"\n",
        "    ]\n",
        "\n",
        "    source_file = None\n",
        "    for candidate in source_candidates:\n",
        "        if Path(candidate).exists():\n",
        "            source_file = candidate\n",
        "            break\n",
        "\n",
        "    if source_file:\n",
        "        print(f\"\\nüéØ Found source file: {source_file}\")\n",
        "\n",
        "        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ\n",
        "        result = merge_submission_files(\n",
        "            submission_path=\"/content/submission.csv\",\n",
        "            source_path=source_file,\n",
        "            output_path=\"/content/final_submission.csv\"\n",
        "        )\n",
        "\n",
        "        if result is not None:\n",
        "            print(\"\\nüéâ Merge completed successfully!\")\n",
        "            print(\"üìÅ Final files:\")\n",
        "            !ls -la /content/*.csv\n",
        "        else:\n",
        "            print(\"\\n‚ùå Merge failed!\")\n",
        "\n",
        "    else:\n",
        "        print(\"\\n‚ùå No source file found for white balance values!\")\n",
        "        print(\"Please specify paths manually:\")\n",
        "\n",
        "        submission_path = input(\"Enter submission file path: \").strip() or \"/content/submission.csv\"\n",
        "        source_path = input(\"Enter source file path: \").strip()\n",
        "        output_path = input(\"Enter output file path: \").strip() or \"/content/merged_submission.csv\"\n",
        "\n",
        "        if Path(submission_path).exists() and Path(source_path).exists():\n",
        "            merge_submission_files(submission_path, source_path, output_path)\n",
        "        else:\n",
        "            print(\"‚ùå Files not found!\")\n",
        "\n",
        "# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ Colab\n",
        "def show_csv_preview():\n",
        "    \"\"\"–ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–µ–≤—å—é –≤—Å–µ—Ö CSV —Ñ–∞–π–ª–æ–≤\"\"\"\n",
        "    csv_files = list(Path(\"/content\").glob(\"*.csv\"))\n",
        "\n",
        "    for csv_file in csv_files:\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"üìÑ {csv_file.name}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        try:\n",
        "            df = pd.read_csv(csv_file)\n",
        "            print(f\"Shape: {df.shape}\")\n",
        "            print(f\"Columns: {list(df.columns)}\")\n",
        "            print(\"\\nFirst 2 rows:\")\n",
        "            print(df.head(2))\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading: {e}\")\n",
        "\n",
        "# –ó–∞–ø—É—Å–∫\n",
        "if __name__ == \"__main__\":\n",
        "    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–∞–π–ª—ã\n",
        "    show_csv_preview()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2mVY95Omadj",
        "outputId": "1dc171ce-9df4-48d0-a4c6-1b49eeefe78d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "üìÑ test.csv\n",
            "==================================================\n",
            "Shape: (145, 1)\n",
            "Columns: ['names']\n",
            "\n",
            "First 2 rows:\n",
            "                names\n",
            "0  test_imgs/0001.png\n",
            "1  test_imgs/0015.png\n",
            "\n",
            "==================================================\n",
            "üìÑ submission.csv\n",
            "==================================================\n",
            "Shape: (145, 4)\n",
            "Columns: ['names', 'wp_r', 'wp_g', 'wp_b']\n",
            "\n",
            "First 2 rows:\n",
            "                names      wp_r      wp_g      wp_b\n",
            "0  test_imgs/0001.png  0.393742  0.610143  0.786508\n",
            "1  test_imgs/0015.png  0.738509  0.593700  0.253388\n",
            "\n",
            "==================================================\n",
            "üìÑ final_submission.csv\n",
            "==================================================\n",
            "Shape: (145, 4)\n",
            "Columns: ['image_path', 'wp_r', 'wp_g', 'wp_b']\n",
            "\n",
            "First 2 rows:\n",
            "  image_path     wp_r  wp_g  wp_b\n",
            "0   0001.png  65535.0   0.0   0.0\n",
            "1   0015.png  65535.0   0.0   0.0\n",
            "\n",
            "==================================================\n",
            "üìÑ train.csv\n",
            "==================================================\n",
            "Shape: (570, 4)\n",
            "Columns: ['names', 'wp_r', 'wp_g', 'wp_b']\n",
            "\n",
            "First 2 rows:\n",
            "                 names      wp_r      wp_g      wp_b\n",
            "0  train_imgs/0000.png  0.173683  0.508642  0.215429\n",
            "1  train_imgs/0002.png  0.266894  0.956725  0.577948\n",
            "\n",
            "============================================================\n",
            "============================================================\n",
            "üìä SUBISSION FILE MERGER\n",
            "============================================================\n",
            "üîç Checking available files:\n",
            "‚úÖ /content/submission.csv\n",
            "‚ùå /content/you1.csv\n",
            "‚úÖ /content/train.csv\n",
            "\n",
            "üéØ Found source file: /content/train.csv\n",
            "üîç Reading files...\n",
            "‚úÖ Submission file loaded: 145 rows\n",
            "   Columns: ['names', 'wp_r', 'wp_g', 'wp_b']\n",
            "‚úÖ Source file loaded: 570 rows\n",
            "   Columns: ['names', 'wp_r', 'wp_g', 'wp_b']\n",
            "‚ö†Ô∏è  Warning: Different number of rows!\n",
            "   Submission: 145 rows\n",
            "   Source: 570 rows\n",
            "   Using first 145 rows from each file\n",
            "‚ÑπÔ∏è  Using first column as image_path: names\n",
            "\n",
            "üîÑ Merging data...\n",
            "‚úÖ Merged file saved: /content/final_submission.csv\n",
            "üìä Result shape: (145, 4)\n",
            "üìã Columns: ['image_path', 'wp_r', 'wp_g', 'wp_b']\n",
            "\n",
            "üìÑ First 5 rows:\n",
            "           image_path      wp_r      wp_g      wp_b\n",
            "0  test_imgs/0001.png  0.173683  0.508642  0.215429\n",
            "1  test_imgs/0015.png  0.266894  0.956725  0.577948\n",
            "2  test_imgs/0018.png  0.146930  0.495538  0.265573\n",
            "3  test_imgs/0019.png  0.218046  0.712538  0.402101\n",
            "4  test_imgs/0020.png  0.070384  0.183209  0.125570\n",
            "\n",
            "üéâ Merge completed successfully!\n",
            "üìÅ Final files:\n",
            "-rw-r--r-- 1 root root  6696 Sep  1 14:06 /content/final_submission.csv\n",
            "-rw-r--r-- 1 root root 11167 Sep  1 12:59 /content/submission.csv\n",
            "-rw-r--r-- 1 root root  2761 Sep  1 12:59 /content/test.csv\n",
            "-rw-r--r-- 1 root root 43527 Sep  1 12:56 /content/train.csv\n"
          ]
        }
      ]
    }
  ]
}