{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mW-ERIYwAHeA",
        "outputId": "20e5ec49-6847-41a8-e37a-b43bb89c2f2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded white points from CSV: 570 entries\n",
            "Common files: 0\n",
            "Dataset created: 0 images, 0 histograms\n",
            "Error: No valid samples found in dataset!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class ImageHistogramDataset(Dataset):\n",
        "    \"\"\"Датасет для изображений и соответствующих гистограмм\"\"\"\n",
        "\n",
        "    def __init__(self, images_dir, histograms_dir, csv_path=None, transform=None, img_size=512):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            images_dir (str): Путь к папке с изображениями\n",
        "            histograms_dir (str): Путь к папке с гистограммами\n",
        "            csv_path (str, optional): Путь к CSV файлу с точками белого\n",
        "            transform (callable, optional): Трансформы для изображений\n",
        "            img_size (int): Размер изображения для resize\n",
        "        \"\"\"\n",
        "        self.images_dir = Path(images_dir)\n",
        "        self.histograms_dir = Path(histograms_dir)\n",
        "        self.transform = transform\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # Проверяем существование папок\n",
        "        \"\"\"if not self.images_dir.exists():\n",
        "            raise ValueError(f\"Images directory not found: {images_dir}\")\n",
        "        if not self.histograms_dir.exists():\n",
        "            raise ValueError(f\"Histograms directory not found: {histograms_dir}\")\"\"\"\n",
        "\n",
        "        # Получаем список файлов\n",
        "        self.image_files = self._get_image_files()\n",
        "        self.histogram_files = self._get_histogram_files()\n",
        "\n",
        "        # Загружаем white points из CSV если есть\n",
        "        self.white_points = self._load_white_points(csv_path)\n",
        "\n",
        "        # Проверяем соответствие файлов\n",
        "        self._validate_files()\n",
        "\n",
        "        print(f\"Dataset created: {len(self.image_files)} images, {len(self.histogram_files)} histograms\")\n",
        "\n",
        "    def _get_image_files(self):\n",
        "        \"\"\"Получаем список изображений\"\"\"\n",
        "        image_extensions = ['.png', '.jpg', '.jpeg', '.tiff', '.tif', '.bmp']\n",
        "        image_files = []\n",
        "\n",
        "        for ext in image_extensions:\n",
        "            image_files.extend(list(self.images_dir.glob(f'*{ext}')))\n",
        "            image_files.extend(list(self.images_dir.glob(f'*{ext.upper()}')))\n",
        "\n",
        "        # Сортируем по имени для consistency\n",
        "        image_files.sort(key=lambda x: x.name)\n",
        "        return image_files\n",
        "\n",
        "    def _get_histogram_files(self):\n",
        "        \"\"\"Получаем список гистограмм\"\"\"\n",
        "        histogram_extensions = ['.png', '.jpg', '.jpeg', '.npy']\n",
        "        histogram_files = []\n",
        "\n",
        "        for ext in histogram_extensions:\n",
        "            histogram_files.extend(list(self.histograms_dir.glob(f'*{ext}')))\n",
        "            histogram_files.extend(list(self.histograms_dir.glob(f'*{ext.upper()}')))\n",
        "\n",
        "        histogram_files.sort(key=lambda x: x.name)\n",
        "        return histogram_files\n",
        "\n",
        "    def _load_white_points(self, csv_path):\n",
        "        \"\"\"Загружаем точки белого из CSV\"\"\"\n",
        "        white_points = {}\n",
        "\n",
        "        if csv_path and os.path.exists(csv_path):\n",
        "            try:\n",
        "                df = pd.read_csv(csv_path)\n",
        "                print(f\"Loaded white points from CSV: {len(df)} entries\")\n",
        "\n",
        "                # Определяем колонки\n",
        "                image_col = None\n",
        "                wp_cols = ['wp_r', 'wp_g', 'wp_b']\n",
        "\n",
        "                for col in df.columns:\n",
        "                    if 'image' in col.lower() or 'path' in col.lower() or 'name' in col.lower():\n",
        "                        image_col = col\n",
        "                        break\n",
        "\n",
        "                if image_col is None:\n",
        "                    image_col = df.columns[0]\n",
        "\n",
        "                # Создаем словарь {filename: [wp_r, wp_g, wp_b]}\n",
        "                for _, row in df.iterrows():\n",
        "                    filename = Path(row[image_col]).name\n",
        "                    wp_values = [row.get(col, 32768.0) for col in wp_cols]\n",
        "                    white_points[filename] = wp_values\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading CSV: {e}\")\n",
        "\n",
        "        return white_points\n",
        "\n",
        "    def _validate_files(self):\n",
        "        \"\"\"Проверяем соответствие изображений и гистограмм\"\"\"\n",
        "        # Получаем имена файлов без расширений\n",
        "        image_names = {f.stem for f in self.image_files}\n",
        "        histogram_names = {f.stem for f in self.histogram_files}\n",
        "\n",
        "        # Общие файлы\n",
        "        common_names = image_names & histogram_names\n",
        "        print(f\"Common files: {len(common_names)}\")\n",
        "\n",
        "        # Фильтруем только соответствующие файлы\n",
        "        self.image_files = [f for f in self.image_files if f.stem in common_names]\n",
        "        self.histogram_files = [f for f in self.histogram_files if f.stem in common_names]\n",
        "\n",
        "        # Сортируем чтобы порядок совпадал\n",
        "        self.image_files.sort(key=lambda x: x.stem)\n",
        "        self.histogram_files.sort(key=lambda x: x.stem)\n",
        "\n",
        "    def _read_image(self, image_path):\n",
        "        \"\"\"Чтение и обработка изображения\"\"\"\n",
        "        try:\n",
        "            # Пробуем разные способы чтения\n",
        "            img = cv2.imread(str(image_path), cv2.IMREAD_UNCHANGED)\n",
        "            if img is None:\n",
        "                img = cv2.imread(str(image_path), cv2.IMREAD_COLOR)\n",
        "\n",
        "            if img is None:\n",
        "                raise ValueError(f\"Cannot read image: {image_path}\")\n",
        "\n",
        "            # Конвертируем в float и нормализуем\n",
        "            if img.dtype == np.uint16:\n",
        "                img = img.astype(np.float32) / 65535.0\n",
        "            elif img.dtype == np.uint8:\n",
        "                img = img.astype(np.float32) / 255.0\n",
        "\n",
        "            # BGR to RGB\n",
        "            if img.shape[-1] == 3:\n",
        "                img = img[..., ::-1]\n",
        "\n",
        "            # Resize\n",
        "            if img.shape[0] != self.img_size or img.shape[1] != self.img_size:\n",
        "                img = cv2.resize(img, (self.img_size, self.img_size))\n",
        "\n",
        "            return img\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading image {image_path}: {e}\")\n",
        "            return np.zeros((self.img_size, self.img_size, 3), dtype=np.float32)\n",
        "\n",
        "    def _read_histogram(self, histogram_path):\n",
        "        \"\"\"Чтение гистограммы\"\"\"\n",
        "        try:\n",
        "            if histogram_path.suffix.lower() in ['.npy']:\n",
        "                hist = np.load(histogram_path)\n",
        "            else:\n",
        "                hist = cv2.imread(str(histogram_path), cv2.IMREAD_GRAYSCALE)\n",
        "                if hist is None:\n",
        "                    hist = np.zeros((128, 128), dtype=np.float32)\n",
        "                else:\n",
        "                    hist = hist.astype(np.float32) / 255.0\n",
        "\n",
        "            return hist\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading histogram {histogram_path}: {e}\")\n",
        "            return np.zeros((128, 128), dtype=np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            image_path = self.image_files[idx]\n",
        "            histogram_path = self.histogram_files[idx]\n",
        "\n",
        "            # Чтение данных\n",
        "            image = self._read_image(image_path)\n",
        "            histogram = self._read_histogram(histogram_path)\n",
        "\n",
        "            # White point\n",
        "            filename = image_path.stem\n",
        "            if filename in self.white_points:\n",
        "                wp_r, wp_g, wp_b = self.white_points[filename]\n",
        "            else:\n",
        "                wp_r, wp_g, wp_b = 32768.0, 32768.0, 32768.0\n",
        "\n",
        "            # Нормализация white point к [0, 1]\n",
        "            white_point = np.array([wp_r, wp_g, wp_b], dtype=np.float32) / 65535.0\n",
        "\n",
        "            # Преобразование в tensor\n",
        "            image_tensor = torch.from_numpy(image.transpose(2, 0, 1)).float()\n",
        "            hist_tensor = torch.from_numpy(histogram).float().unsqueeze(0)  # Добавляем channel dimension\n",
        "            wp_tensor = torch.from_numpy(white_point).float()\n",
        "\n",
        "            # Применяем трансформы\n",
        "            if self.transform:\n",
        "                image_tensor = self.transform(image_tensor)\n",
        "\n",
        "            return image_tensor, hist_tensor, wp_tensor\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading sample {idx}: {e}\")\n",
        "            # Возвращаем dummy данные\n",
        "            dummy_image = torch.randn(3, self.img_size, self.img_size)\n",
        "            dummy_hist = torch.zeros(1, 128, 128)\n",
        "            dummy_wp = torch.tensor([0.5, 0.5, 0.5])\n",
        "            return dummy_image, dummy_hist, dummy_wp\n",
        "\n",
        "def create_data_loaders(images_dir, histograms_dir, csv_path=None,\n",
        "                       batch_size=8, val_size=0.2, img_size=512, transform=None):\n",
        "    \"\"\"Создает DataLoader'ы для обучения\"\"\"\n",
        "\n",
        "    # Создаем полный датасет\n",
        "    dataset = ImageHistogramDataset(\n",
        "        images_dir=images_dir,\n",
        "        histograms_dir=histograms_dir,\n",
        "        csv_path=csv_path,\n",
        "        transform=transform,\n",
        "        img_size=img_size\n",
        "    )\n",
        "\n",
        "    if len(dataset) == 0:\n",
        "        raise ValueError(\"No valid samples found in dataset!\")\n",
        "\n",
        "    # Разделение на train/val\n",
        "    indices = list(range(len(dataset)))\n",
        "    train_indices, val_indices = train_test_split(\n",
        "        indices, test_size=val_size, random_state=42, shuffle=True\n",
        "    )\n",
        "\n",
        "    # Создаем подвыборки\n",
        "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
        "    val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
        "\n",
        "    print(f\"Train samples: {len(train_indices)}, Val samples: {len(val_indices)}\")\n",
        "\n",
        "    # DataLoaders\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=min(batch_size, len(train_dataset)),\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=min(batch_size, len(val_dataset)),\n",
        "        shuffle=False,\n",
        "        num_workers=1,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "# Пример использования\n",
        "def example_usage():\n",
        "    \"\"\"Пример использования датасета\"\"\"\n",
        "\n",
        "    # Пути к вашим папкам\n",
        "    IMAGES_DIR = \"/content/train_imgs\"\n",
        "    HISTOGRAMS_DIR = \"/content/train_histograms\"\n",
        "    CSV_PATH = \"/content/train.csv\"\n",
        "\n",
        "    try:\n",
        "        # Создаем DataLoader'ы\n",
        "        train_loader, val_loader = create_data_loaders(\n",
        "            images_dir=IMAGES_DIR,\n",
        "            histograms_dir=HISTOGRAMS_DIR,\n",
        "            csv_path=CSV_PATH,\n",
        "            batch_size=8,\n",
        "            val_size=0.2,\n",
        "            img_size=512\n",
        "        )\n",
        "\n",
        "        print(f\"Successfully created data loaders!\")\n",
        "        print(f\"Train batches: {len(train_loader)}\")\n",
        "        print(f\"Val batches: {len(val_loader)}\")\n",
        "\n",
        "        # Проверяем первый батч\n",
        "        for images, hists, white_points in train_loader:\n",
        "            print(f\"Images shape: {images.shape}\")\n",
        "            print(f\"Histograms shape: {hists.shape}\")\n",
        "            print(f\"White points shape: {white_points.shape}\")\n",
        "            print(f\"White points range: {white_points.min():.3f} - {white_points.max():.3f}\")\n",
        "            break\n",
        "\n",
        "        return train_loader, val_loader\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Утилиты для проверки\n",
        "def check_folder_structure(images_dir, histograms_dir):\n",
        "    \"\"\"Проверяет структуру папок\"\"\"\n",
        "    print(\"🔍 Checking folder structure...\")\n",
        "\n",
        "    images_dir = Path(images_dir)\n",
        "    histograms_dir = Path(histograms_dir)\n",
        "\n",
        "    print(f\"Images directory: {images_dir}\")\n",
        "    if images_dir.exists():\n",
        "        image_files = list(images_dir.glob('*.*'))\n",
        "        print(f\"  Found {len(image_files)} files\")\n",
        "        if image_files:\n",
        "            print(f\"  Example: {image_files[0].name}\")\n",
        "    else:\n",
        "        print(\"  ❌ Does not exist!\")\n",
        "\n",
        "    print(f\"Histograms directory: {histograms_dir}\")\n",
        "    if histograms_dir.exists():\n",
        "        hist_files = list(histograms_dir.glob('*.*'))\n",
        "        print(f\"  Found {len(hist_files)} files\")\n",
        "        if hist_files:\n",
        "            print(f\"  Example: {hist_files[0].name}\")\n",
        "    else:\n",
        "        print(\"  ❌ Does not exist!\")\n",
        "\n",
        "# Быстрый старт\n",
        "def quick_start():\n",
        "    \"\"\"Быстрое создание датасета\"\"\"\n",
        "    # Замените на ваши пути\n",
        "    images_dir = input(\"Enter images directory path: \").strip() or \"/content/train_imgs\"\n",
        "    histograms_dir = input(\"Enter histograms directory path: \").strip() or \"/content/train_histograms\"\n",
        "    csv_path = input(\"Enter CSV path (optional): \").strip() or None\n",
        "\n",
        "    check_folder_structure(images_dir, histograms_dir)\n",
        "\n",
        "    return create_data_loaders(images_dir, histograms_dir, csv_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Запуск примера\n",
        "    train_loader, val_loader = example_usage()\n",
        "\n",
        "    # Или быстрый старт\n",
        "    # train_loader, val_loader = quick_start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class ImageHistogramDataset(Dataset):\n",
        "    \"\"\"Датасет для изображений и соответствующих гистограмм\"\"\"\n",
        "\n",
        "    def __init__(self, images_dir, histograms_dir, csv_path=None, transform=None, img_size=512):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            images_dir (str): Путь к папке с изображениями\n",
        "            histograms_dir (str): Путь к папке с гистограммами\n",
        "            csv_path (str, optional): Путь к CSV файлу с точками белого\n",
        "            transform (callable, optional): Трансформы для изображений\n",
        "            img_size (int): Размер изображения для resize\n",
        "        \"\"\"\n",
        "        self.images_dir = Path(images_dir)\n",
        "        self.histograms_dir = Path(histograms_dir)\n",
        "        self.transform = transform\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # Проверяем существование папок\n",
        "        if not self.images_dir.exists():\n",
        "            raise ValueError(f\"Images directory not found: {images_dir}\")\n",
        "        if not self.histograms_dir.exists():\n",
        "            raise ValueError(f\"Histograms directory not found: {histograms_dir}\")\n",
        "\n",
        "        # Получаем список файлов\n",
        "        self.image_files = self._get_image_files()\n",
        "        self.histogram_files = self._get_histogram_files()\n",
        "\n",
        "        # Загружаем white points из CSV если есть\n",
        "        self.white_points = self._load_white_points(csv_path)\n",
        "\n",
        "        # Проверяем соответствие файлов\n",
        "        self._validate_files()\n",
        "\n",
        "        print(f\"Dataset created: {len(self.image_files)} images, {len(self.histogram_files)} histograms\")\n",
        "\n",
        "    def _get_image_files(self):\n",
        "        \"\"\"Получаем список изображений\"\"\"\n",
        "        image_extensions = ['.png', '.jpg', '.jpeg', '.tiff', '.tif', '.bmp']\n",
        "        image_files = []\n",
        "\n",
        "        for ext in image_extensions:\n",
        "            image_files.extend(list(self.images_dir.glob(f'*{ext}')))\n",
        "            image_files.extend(list(self.images_dir.glob(f'*{ext.upper()}')))\n",
        "\n",
        "        # Сортируем по имени для consistency\n",
        "        image_files.sort(key=lambda x: x.name)\n",
        "        return image_files\n",
        "\n",
        "    def _get_histogram_files(self):\n",
        "        \"\"\"Получаем список гистограмм\"\"\"\n",
        "        histogram_extensions = ['.png', '.jpg', '.jpeg', '.npy']\n",
        "        histogram_files = []\n",
        "\n",
        "        for ext in histogram_extensions:\n",
        "            histogram_files.extend(list(self.histograms_dir.glob(f'*{ext}')))\n",
        "            histogram_files.extend(list(self.histograms_dir.glob(f'*{ext.upper()}')))\n",
        "\n",
        "        histogram_files.sort(key=lambda x: x.name)\n",
        "        return histogram_files\n",
        "\n",
        "    def _load_white_points(self, csv_path):\n",
        "        \"\"\"Загружаем точки белого из CSV\"\"\"\n",
        "        white_points = {}\n",
        "\n",
        "        if csv_path and os.path.exists(csv_path):\n",
        "            try:\n",
        "                df = pd.read_csv(csv_path)\n",
        "                print(f\"Loaded white points from CSV: {len(df)} entries\")\n",
        "\n",
        "                # Определяем колонки\n",
        "                image_col = None\n",
        "                wp_cols = ['wp_r', 'wp_g', 'wp_b']\n",
        "\n",
        "                for col in df.columns:\n",
        "                    if 'image' in col.lower() or 'path' in col.lower() or 'name' in col.lower():\n",
        "                        image_col = col\n",
        "                        break\n",
        "\n",
        "                if image_col is None:\n",
        "                    image_col = df.columns[0]\n",
        "\n",
        "                # Создаем словарь {filename: [wp_r, wp_g, wp_b]}\n",
        "                for _, row in df.iterrows():\n",
        "                    filename = Path(row[image_col]).name\n",
        "                    wp_values = [row.get(col, 32768.0) for col in wp_cols]\n",
        "                    white_points[filename] = wp_values\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading CSV: {e}\")\n",
        "\n",
        "        return white_points\n",
        "\n",
        "    def _validate_files(self):\n",
        "        \"\"\"Проверяем соответствие изображений и гистограмм\"\"\"\n",
        "        # Получаем имена файлов без расширений\n",
        "        image_names = {f.stem for f in self.image_files}\n",
        "        histogram_names = {f.stem for f in self.histogram_files}\n",
        "\n",
        "        # Общие файлы\n",
        "        common_names = image_names & histogram_names\n",
        "        print(f\"Common files: {len(common_names)}\")\n",
        "\n",
        "        # Фильтруем только соответствующие файлы\n",
        "        self.image_files = [f for f in self.image_files if f.stem in common_names]\n",
        "        self.histogram_files = [f for f in self.histogram_files if f.stem in common_names]\n",
        "\n",
        "        # Сортируем чтобы порядок совпадал\n",
        "        self.image_files.sort(key=lambda x: x.stem)\n",
        "        self.histogram_files.sort(key=lambda x: x.stem)\n",
        "\n",
        "    def _read_image(self, image_path):\n",
        "        \"\"\"Чтение и обработка изображения\"\"\"\n",
        "        try:\n",
        "            # Пробуем разные способы чтения\n",
        "            img = cv2.imread(str(image_path), cv2.IMREAD_UNCHANGED)\n",
        "            if img is None:\n",
        "                img = cv2.imread(str(image_path), cv2.IMREAD_COLOR)\n",
        "\n",
        "            if img is None:\n",
        "                raise ValueError(f\"Cannot read image: {image_path}\")\n",
        "\n",
        "            # Конвертируем в float и нормализуем\n",
        "            if img.dtype == np.uint16:\n",
        "                img = img.astype(np.float32) / 65535.0\n",
        "            elif img.dtype == np.uint8:\n",
        "                img = img.astype(np.float32) / 255.0\n",
        "\n",
        "            # BGR to RGB\n",
        "            if img.shape[-1] == 3:\n",
        "                img = img[..., ::-1]\n",
        "\n",
        "            # Resize\n",
        "            if img.shape[0] != self.img_size or img.shape[1] != self.img_size:\n",
        "                img = cv2.resize(img, (self.img_size, self.img_size))\n",
        "\n",
        "            return img\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading image {image_path}: {e}\")\n",
        "            return np.zeros((self.img_size, self.img_size, 3), dtype=np.float32)\n",
        "\n",
        "    def _read_histogram(self, histogram_path):\n",
        "        \"\"\"Чтение гистограммы\"\"\"\n",
        "        try:\n",
        "            if histogram_path.suffix.lower() in ['.npy']:\n",
        "                hist = np.load(histogram_path)\n",
        "            else:\n",
        "                hist = cv2.imread(str(histogram_path), cv2.IMREAD_GRAYSCALE)\n",
        "                if hist is None:\n",
        "                    hist = np.zeros((128, 128), dtype=np.float32)\n",
        "                else:\n",
        "                    hist = hist.astype(np.float32) / 255.0\n",
        "\n",
        "            return hist\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading histogram {histogram_path}: {e}\")\n",
        "            return np.zeros((128, 128), dtype=np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            image_path = self.image_files[idx]\n",
        "            histogram_path = self.histogram_files[idx]\n",
        "\n",
        "            # Чтение данных\n",
        "            image = self._read_image(image_path)\n",
        "            histogram = self._read_histogram(histogram_path)\n",
        "\n",
        "            # White point\n",
        "            filename = image_path.stem\n",
        "            if filename in self.white_points:\n",
        "                wp_r, wp_g, wp_b = self.white_points[filename]\n",
        "            else:\n",
        "                wp_r, wp_g, wp_b = 32768.0, 32768.0, 32768.0\n",
        "\n",
        "            # Нормализация white point к [0, 1]\n",
        "            white_point = np.array([wp_r, wp_g, wp_b], dtype=np.float32) / 65535.0\n",
        "\n",
        "            # Преобразование в tensor\n",
        "            image_tensor = torch.from_numpy(image.transpose(2, 0, 1)).float()\n",
        "            hist_tensor = torch.from_numpy(histogram).float().unsqueeze(0)  # Добавляем channel dimension\n",
        "            wp_tensor = torch.from_numpy(white_point).float()\n",
        "\n",
        "            # Применяем трансформы\n",
        "            if self.transform:\n",
        "                image_tensor = self.transform(image_tensor)\n",
        "\n",
        "            return image_tensor, hist_tensor, wp_tensor\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading sample {idx}: {e}\")\n",
        "            # Возвращаем dummy данные\n",
        "            dummy_image = torch.randn(3, self.img_size, self.img_size)\n",
        "            dummy_hist = torch.zeros(1, 128, 128)\n",
        "            dummy_wp = torch.tensor([0.5, 0.5, 0.5])\n",
        "            return dummy_image, dummy_hist, dummy_wp\n",
        "\n",
        "def create_data_loaders(images_dir, histograms_dir, csv_path=None,\n",
        "                       batch_size=8, val_size=0.2, img_size=512, transform=None):\n",
        "    \"\"\"Создает DataLoader'ы для обучения\"\"\"\n",
        "\n",
        "    # Создаем полный датасет\n",
        "    dataset = ImageHistogramDataset(\n",
        "        images_dir=images_dir,\n",
        "        histograms_dir=histograms_dir,\n",
        "        csv_path=csv_path,\n",
        "        transform=transform,\n",
        "        img_size=img_size\n",
        "    )\n",
        "\n",
        "    if len(dataset) == 0:\n",
        "        raise ValueError(\"No valid samples found in dataset!\")\n",
        "\n",
        "    # Разделение на train/val\n",
        "    indices = list(range(len(dataset)))\n",
        "    train_indices, val_indices = train_test_split(\n",
        "        indices, test_size=val_size, random_state=42, shuffle=True\n",
        "    )\n",
        "\n",
        "    # Создаем подвыборки\n",
        "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
        "    val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
        "\n",
        "    print(f\"Train samples: {len(train_indices)}, Val samples: {len(val_indices)}\")\n",
        "\n",
        "    # DataLoaders\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=min(batch_size, len(train_dataset)),\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=min(batch_size, len(val_dataset)),\n",
        "        shuffle=False,\n",
        "        num_workers=1,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "# Пример использования\n",
        "def example_usage():\n",
        "    \"\"\"Пример использования датасета\"\"\"\n",
        "\n",
        "    # Пути к вашим папкам\n",
        "    IMAGES_DIR = \"/content/train_imgs\"\n",
        "    HISTOGRAMS_DIR = \"/content/екфшт_ршыещпкфьы2\"\n",
        "    CSV_PATH = \"/content/train.csv\"\n",
        "\n",
        "    try:\n",
        "        # Создаем DataLoader'ы\n",
        "        train_loader, val_loader = create_data_loaders(\n",
        "            images_dir='/content/train_imgs2',\n",
        "            histograms_dir='/content/train_histograms',\n",
        "            csv_path=\"/content/train.csv\",\n",
        "            batch_size=8,\n",
        "            val_size=0.2,\n",
        "            img_size=512\n",
        "        )\n",
        "\n",
        "        print(f\"Successfully created data loaders!\")\n",
        "        print(f\"Train batches: {len(train_loader)}\")\n",
        "        print(f\"Val batches: {len(val_loader)}\")\n",
        "\n",
        "        # Проверяем первый батч\n",
        "        for images, hists, white_points in train_loader:\n",
        "            print(f\"Images shape: {images.shape}\")\n",
        "            print(f\"Histograms shape: {hists.shape}\")\n",
        "            print(f\"White points shape: {white_points.shape}\")\n",
        "            print(f\"White points range: {white_points.min():.3f} - {white_points.max():.3f}\")\n",
        "            break\n",
        "\n",
        "        return train_loader, val_loader\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Утилиты для проверки\n",
        "def check_folder_structure(images_dir, histograms_dir):\n",
        "    \"\"\"Проверяет структуру папок\"\"\"\n",
        "    print(\"🔍 Checking folder structure...\")\n",
        "\n",
        "    images_dir = Path(images_dir)\n",
        "    histograms_dir = Path(histograms_dir)\n",
        "\n",
        "    print(f\"Images directory: {images_dir}\")\n",
        "    if images_dir.exists():\n",
        "        image_files = list(images_dir.glob('*.*'))\n",
        "        print(f\"  Found {len(image_files)} files\")\n",
        "        if image_files:\n",
        "            print(f\"  Example: {image_files[0].name}\")\n",
        "    else:\n",
        "        print(\"  ❌ Does not exist!\")\n",
        "\n",
        "    print(f\"Histograms directory: {histograms_dir}\")\n",
        "    if histograms_dir.exists():\n",
        "        hist_files = list(histograms_dir.glob('*.*'))\n",
        "        print(f\"  Found {len(hist_files)} files\")\n",
        "        if hist_files:\n",
        "            print(f\"  Example: {hist_files[0].name}\")\n",
        "    else:\n",
        "        print(\"  ❌ Does not exist!\")\n",
        "\n",
        "# Быстрый старт\n",
        "def quick_start():\n",
        "    \"\"\"Быстрое создание датасета\"\"\"\n",
        "    # Замените на ваши пути\n",
        "    images_dir = input(\"Enter images directory path: \").strip() or \"/content/train_imgs\"\n",
        "    histograms_dir = input(\"Enter histograms directory path: \").strip() or \"/content/train_histograms\"\n",
        "    csv_path = input(\"Enter CSV path (optional): \").strip() or None\n",
        "\n",
        "    check_folder_structure(images_dir, histograms_dir)\n",
        "\n",
        "    return create_data_loaders(images_dir, histograms_dir, csv_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Запуск примера\n",
        "    train_loader, val_loader = example_usage()\n",
        "\n",
        "    # Или быстрый старт\n",
        "    # train_loader, val_loader = quick_start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgaTKaMPYHDU",
        "outputId": "b51cba49-e802-4da8-d98d-a8daeeba128c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded white points from CSV: 570 entries\n",
            "Common files: 84\n",
            "Dataset created: 84 images, 84 histograms\n",
            "Train samples: 67, Val samples: 17\n",
            "Successfully created data loaders!\n",
            "Train batches: 9\n",
            "Val batches: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images shape: torch.Size([8, 3, 512, 512])\n",
            "Histograms shape: torch.Size([8, 1, 128, 128])\n",
            "White points shape: torch.Size([8, 3])\n",
            "White points range: 0.500 - 0.500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "class Dist2HistLoss(nn.Module):\n",
        "    \"\"\"Функция потерь, соответствующая метрике Dist2Hist\"\"\"\n",
        "\n",
        "    def __init__(self, alpha=0.6, beta=0.3, gamma=0.1, eps=1e-7):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            alpha: вес угловой ошибки (основной компонент Dist2Hist)\n",
        "            beta: вес хроматического расстояния\n",
        "            gamma: вес MSE для стабилизации\n",
        "            eps: маленькое значение для численной стабильности\n",
        "        \"\"\"\n",
        "        super(Dist2HistLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.gamma = gamma\n",
        "        self.eps = eps\n",
        "\n",
        "    def angular_loss(self, pred, target):\n",
        "        \"\"\"Угловая ошибка между векторами\"\"\"\n",
        "        # Нормализуем векторы\n",
        "        pred_norm = pred / (torch.norm(pred, dim=1, keepdim=True) + self.eps)\n",
        "        target_norm = target / (torch.norm(target, dim=1, keepdim=True) + self.eps)\n",
        "\n",
        "        # Косинусная схожесть\n",
        "        cosine_sim = torch.sum(pred_norm * target_norm, dim=1)\n",
        "        cosine_sim = torch.clamp(cosine_sim, -1 + self.eps, 1 - self.eps)\n",
        "\n",
        "        # Угол в радианах\n",
        "        angle = torch.acos(cosine_sim)\n",
        "        return torch.mean(angle)\n",
        "\n",
        "    def chromatic_loss(self, pred, target):\n",
        "        \"\"\"Расстояние в хроматическом пространстве\"\"\"\n",
        "        # Преобразование RGB в хроматические координаты (α, β)\n",
        "        pred_alpha = pred[:, 0] / (torch.sum(pred, dim=1) + self.eps)\n",
        "        pred_beta = pred[:, 1] / (torch.sum(pred, dim=1) + self.eps)\n",
        "\n",
        "        target_alpha = target[:, 0] / (torch.sum(target, dim=1) + self.eps)\n",
        "        target_beta = target[:, 1] / (torch.sum(target, dim=1) + self.eps)\n",
        "\n",
        "        # Евклидово расстояние в хроматическом пространстве\n",
        "        alpha_diff = pred_alpha - target_alpha\n",
        "        beta_diff = pred_beta - target_beta\n",
        "        chroma_dist = torch.sqrt(alpha_diff**2 + beta_diff**2 + self.eps)\n",
        "\n",
        "        return torch.mean(chroma_dist)\n",
        "\n",
        "    def mse_loss(self, pred, target):\n",
        "        \"\"\"MSE для стабилизации обучения\"\"\"\n",
        "        return nn.MSELoss()(pred, target)\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        \"\"\"\n",
        "        Вычисление общей потери\n",
        "\n",
        "        Args:\n",
        "            pred: предсказанные точки белого [batch_size, 3] в диапазоне [0, 1]\n",
        "            target: истинные точки белого [batch_size, 3] в диапазоне [0, 1]\n",
        "\n",
        "        Returns:\n",
        "            Комбинированная потеря, соответствующая метрике Dist2Hist\n",
        "        \"\"\"\n",
        "        angular = self.angular_loss(pred, target)\n",
        "        chroma = self.chromatic_loss(pred, target)\n",
        "        mse = self.mse_loss(pred, target)\n",
        "\n",
        "        # Комбинируем с весами, соответствующими метрике Dist2Hist\n",
        "        total_loss = (self.alpha * angular +\n",
        "                     self.beta * chroma +\n",
        "                     self.gamma * mse)\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "class WhiteBalanceModel(nn.Module):\n",
        "    \"\"\"Модель для предсказания точки белого\"\"\"\n",
        "\n",
        "    def __init__(self, pretrained=False):\n",
        "        super(WhiteBalanceModel, self).__init__()\n",
        "\n",
        "        # Используем EfficientNet как энкодер\n",
        "        if pretrained:\n",
        "            from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
        "            self.backbone = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "        else:\n",
        "            from torchvision.models import efficientnet_b0\n",
        "            self.backbone = efficientnet_b0(weights=None)\n",
        "\n",
        "        # Заменяем классификатор на регрессионную голову\n",
        "        in_features = self.backbone.classifier[1].in_features\n",
        "\n",
        "        self.backbone.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.3),\n",
        "            nn.Linear(in_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 3),  # 3 выхода для RGB\n",
        "            nn.Sigmoid()  # Выход в диапазоне [0, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "def setup_device():\n",
        "    \"\"\"Настройка устройства (GPU/CPU)\"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    return device\n",
        "\n",
        "def train_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    \"\"\"Одна эпоха обучения\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch} Training\")\n",
        "\n",
        "    for batch_idx, (images, _, white_points) in enumerate(progress_bar):\n",
        "        images = images.to(device)\n",
        "        white_points = white_points.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, white_points)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Обновление progress bar\n",
        "        progress_bar.set_postfix({\n",
        "            'Loss': f'{loss.item():.6f}',\n",
        "            'Avg Loss': f'{total_loss/(batch_idx+1):.6f}'\n",
        "        })\n",
        "\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "def validate_epoch(model, val_loader, criterion, device, epoch):\n",
        "    \"\"\"Валидация\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    progress_bar = tqdm(val_loader, desc=f\"Epoch {epoch} Validation\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, _, white_points) in enumerate(progress_bar):\n",
        "            images = images.to(device)\n",
        "            white_points = white_points.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, white_points)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            progress_bar.set_postfix({\n",
        "                'Val Loss': f'{loss.item():.6f}',\n",
        "                'Avg Val Loss': f'{total_loss/(batch_idx+1):.6f}'\n",
        "            })\n",
        "\n",
        "    return total_loss / len(val_loader)\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, loss, path):\n",
        "    \"\"\"Сохранение чекпоинта\"\"\"\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss,\n",
        "        'timestamp': datetime.now().isoformat()\n",
        "    }\n",
        "    torch.save(checkpoint, path)\n",
        "    print(f\"Checkpoint saved: {path}\")\n",
        "\n",
        "def load_checkpoint(model, optimizer, checkpoint_path, device):\n",
        "    \"\"\"Загрузка чекпоинта\"\"\"\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        print(f\"Checkpoint loaded from epoch {checkpoint['epoch']}\")\n",
        "        return checkpoint['epoch'], checkpoint['loss']\n",
        "    return 0, float('inf')\n",
        "\n",
        "def create_dummy_dataloaders(batch_size=8, img_size=224, num_samples=100):\n",
        "    \"\"\"Создание dummy dataloaders для тестирования\"\"\"\n",
        "    from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "    # Создаем dummy данные\n",
        "    dummy_images = torch.randn(num_samples, 3, img_size, img_size)\n",
        "    dummy_hists = torch.randn(num_samples, 1, 128, 128)  # Гистограммы\n",
        "    dummy_white_points = torch.rand(num_samples, 3)  # Точки белого в [0, 1]\n",
        "\n",
        "    # Разделение на train/val\n",
        "    split = int(0.8 * num_samples)\n",
        "\n",
        "    train_dataset = TensorDataset(dummy_images[:split], dummy_hists[:split], dummy_white_points[:split])\n",
        "    val_dataset = TensorDataset(dummy_images[split:], dummy_hists[split:], dummy_white_points[split:])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    print(f\"Dummy data: {num_samples} samples\")\n",
        "    return train_loader, val_loader\n",
        "\n",
        "def main():\n",
        "    \"\"\"Основная функция обучения\"\"\"\n",
        "    # Конфигурация\n",
        "    config = {\n",
        "        'batch_size': 1,\n",
        "        'learning_rate': 1e-4,\n",
        "        'num_epochs': 33,\n",
        "        'val_size': 0.2,\n",
        "        'weight_decay': 1e-5,\n",
        "        'pretrained': True,\n",
        "        'checkpoint_path': 'best_model.pth',\n",
        "        'results_dir': 'results',\n",
        "        'img_size': 224\n",
        "    }\n",
        "\n",
        "    # Создание директории для результатов\n",
        "    os.makedirs(config['results_dir'], exist_ok=True)\n",
        "\n",
        "    # Сохранение конфигурации\n",
        "    with open(f\"{config['results_dir']}/config.json\", 'w') as f:\n",
        "        json.dump(config, f, indent=4)\n",
        "\n",
        "    # Настройка устройства\n",
        "    device = setup_device()\n",
        "\n",
        "    # Создание DataLoaders\n",
        "    print(\"Creating data loaders...\")\n",
        "    try:\n",
        "        # Замените на вашу функцию создания датасета\n",
        "\n",
        "\n",
        "        train_loader, val_loader = create_data_loaders(\n",
        "            images_dir=\"/content/train_imgs2\",\n",
        "            histograms_dir=\"/content/train_histograms\",\n",
        "            csv_path=\"/content/train.csv\",\n",
        "            batch_size=config['batch_size'],\n",
        "            val_size=config['val_size'],\n",
        "            img_size=config['img_size']\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating data loaders: {e}\")\n",
        "        print(\"Using dummy data for testing...\")\n",
        "        train_loader, val_loader = create_dummy_dataloaders(\n",
        "            batch_size=config['batch_size'],\n",
        "            img_size=config['img_size']\n",
        "        )\n",
        "\n",
        "    print(f\"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")\n",
        "\n",
        "    # Инициализация модели\n",
        "    print(\"Initializing model...\")\n",
        "    model = WhiteBalanceModel(pretrained=config['pretrained']).to(device)\n",
        "\n",
        "    # Функция потерь - ОСНОВНОЕ ИЗМЕНЕНИЕ\n",
        "    criterion = Dist2HistLoss(alpha=0.6, beta=0.3, gamma=0.1)\n",
        "\n",
        "    # Оптимизатор\n",
        "    optimizer = optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=config['learning_rate'],\n",
        "        weight_decay=config['weight_decay']\n",
        "    )\n",
        "\n",
        "    # Scheduler\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=5\n",
        "    )\n",
        "\n",
        "    # Загрузка чекпоинта если существует\n",
        "    start_epoch, best_loss = load_checkpoint(\n",
        "        model, optimizer, config['checkpoint_path'], device\n",
        "    )\n",
        "\n",
        "    # Обучение\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    learning_rates = []\n",
        "\n",
        "    print(\"Starting training with Dist2Hist loss...\")\n",
        "    for epoch in range(start_epoch, config['num_epochs']):\n",
        "        print(f\"\\nEpoch {epoch+1}/{config['num_epochs']}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        # Обучение\n",
        "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device, epoch+1)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # Валидация\n",
        "        val_loss = validate_epoch(model, val_loader, criterion, device, epoch+1)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        # Обновление scheduler\n",
        "        scheduler.step(val_loss)\n",
        "        learning_rates.append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "        # Сохранение лучшей модели\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            save_checkpoint(\n",
        "                model, optimizer, epoch, val_loss,\n",
        "                f\"{config['results_dir']}/{config['checkpoint_path']}\"\n",
        "            )\n",
        "\n",
        "        # Сохранение истории обучения\n",
        "        history = {\n",
        "            'train_losses': train_losses,\n",
        "            'val_losses': val_losses,\n",
        "            'learning_rates': learning_rates,\n",
        "            'best_val_loss': best_loss\n",
        "        }\n",
        "\n",
        "        with open(f\"{config['results_dir']}/training_history.json\", 'w') as f:\n",
        "            json.dump(history, f, indent=4)\n",
        "\n",
        "        # Визуализация прогресса\n",
        "        if epoch % 5 == 0 or epoch == config['num_epochs'] - 1:\n",
        "            plt.figure(figsize=(15, 5))\n",
        "\n",
        "            plt.subplot(1, 3, 1)\n",
        "            plt.plot(train_losses, label='Train Loss', marker='o')\n",
        "            plt.plot(val_losses, label='Validation Loss', marker='s')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.title('Training Progress')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "\n",
        "            plt.subplot(1, 3, 2)\n",
        "            plt.plot(learning_rates, label='Learning Rate', marker='^', color='red')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel('Learning Rate')\n",
        "            plt.title('Learning Rate Schedule')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            plt.yscale('log')\n",
        "\n",
        "            plt.subplot(1, 3, 3)\n",
        "            # Показываем компоненты потерь\n",
        "            plt.bar(['Angular', 'Chromatic', 'MSE'],\n",
        "                   [criterion.alpha, criterion.beta, criterion.gamma],\n",
        "                   color=['blue', 'green', 'orange'])\n",
        "            plt.title('Loss Components Weights')\n",
        "            plt.ylabel('Weight')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f\"{config['results_dir']}/training_progress_epoch_{epoch+1}.png\")\n",
        "            plt.close()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}, LR = {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "    print(\"Training completed!\")\n",
        "    print(f\"Best validation loss: {best_loss:.6f}\")\n",
        "\n",
        "    # Финальное сохранение модели\n",
        "    torch.save(model.state_dict(), f\"{config['results_dir']}/final_model.pth\")\n",
        "    print(f\"Final model saved to {config['results_dir']}/final_model.pth\")\n",
        "\n",
        "    return model, train_losses, val_losses\n",
        "\n",
        "# Дополнительные утилиты\n",
        "def test_loss_function():\n",
        "    \"\"\"Тестирование функции потерь\"\"\"\n",
        "    criterion = Dist2HistLoss()\n",
        "\n",
        "    # Тестовые данные\n",
        "    batch_size = 4\n",
        "    pred = torch.rand(batch_size, 3)  # Предсказания в [0, 1]\n",
        "    target = torch.rand(batch_size, 3)  # Цели в [0, 1]\n",
        "\n",
        "    loss = criterion(pred, target)\n",
        "    print(f\"Test loss: {loss.item():.6f}\")\n",
        "\n",
        "    # Компоненты потерь\n",
        "    angular = criterion.angular_loss(pred, target)\n",
        "    chroma = criterion.chromatic_loss(pred, target)\n",
        "    mse = criterion.mse_loss(pred, target)\n",
        "\n",
        "    print(f\"Angular: {angular.item():.6f}\")\n",
        "    print(f\"Chromatic: {chroma.item():.6f}\")\n",
        "    print(f\"MSE: {mse.item():.6f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Тестирование функции потерь\n",
        "    print(\"Testing loss function...\")\n",
        "    test_loss_function()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    # Запуск обучения\n",
        "    model, train_losses, val_losses = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JeWXgY-NHRet",
        "outputId": "57df87f1-c947-4168-f2ba-de9037a4c647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing loss function...\n",
            "Test loss: 0.550855\n",
            "Angular: 0.711987\n",
            "Chromatic: 0.345134\n",
            "MSE: 0.201232\n",
            "\n",
            "============================================================\n",
            "Using device: cpu\n",
            "Creating data loaders...\n",
            "Loaded white points from CSV: 570 entries\n",
            "Common files: 84\n",
            "Dataset created: 84 images, 84 histograms\n",
            "Train samples: 67, Val samples: 17\n",
            "Train batches: 67, Val batches: 17\n",
            "Initializing model...\n",
            "Starting training with Dist2Hist loss...\n",
            "\n",
            "Epoch 1/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1 Training:   0%|          | 0/67 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "Epoch 1 Training: 100%|██████████| 67/67 [00:22<00:00,  3.02it/s, Loss=0.001672, Avg Loss=0.003866]\n",
            "Epoch 1 Validation: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, Val Loss=0.025495, Avg Val Loss=0.010755]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: results/best_model.pth\n",
            "Epoch 1: Train Loss = 0.003866, Val Loss = 0.010755, LR = 1.00e-04\n",
            "\n",
            "Epoch 2/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 Training: 100%|██████████| 67/67 [00:22<00:00,  2.99it/s, Loss=0.002720, Avg Loss=0.003218]\n",
            "Epoch 2 Validation: 100%|██████████| 17/17 [00:01<00:00, 10.07it/s, Val Loss=0.006048, Avg Val Loss=0.005724]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: results/best_model.pth\n",
            "Epoch 2: Train Loss = 0.003218, Val Loss = 0.005724, LR = 1.00e-04\n",
            "\n",
            "Epoch 3/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 Training: 100%|██████████| 67/67 [00:22<00:00,  3.04it/s, Loss=0.001049, Avg Loss=0.002210]\n",
            "Epoch 3 Validation: 100%|██████████| 17/17 [00:01<00:00, 10.03it/s, Val Loss=0.006263, Avg Val Loss=0.005767]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss = 0.002210, Val Loss = 0.005767, LR = 1.00e-04\n",
            "\n",
            "Epoch 4/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 Training: 100%|██████████| 67/67 [00:21<00:00,  3.05it/s, Loss=0.000611, Avg Loss=0.001804]\n",
            "Epoch 4 Validation: 100%|██████████| 17/17 [00:01<00:00,  9.31it/s, Val Loss=0.005970, Avg Val Loss=0.005604]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: results/best_model.pth\n",
            "Epoch 4: Train Loss = 0.001804, Val Loss = 0.005604, LR = 1.00e-04\n",
            "\n",
            "Epoch 5/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 Training: 100%|██████████| 67/67 [00:21<00:00,  3.14it/s, Loss=0.002091, Avg Loss=0.001616]\n",
            "Epoch 5 Validation: 100%|██████████| 17/17 [00:02<00:00,  6.25it/s, Val Loss=0.003224, Avg Val Loss=0.005333]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: results/best_model.pth\n",
            "Epoch 5: Train Loss = 0.001616, Val Loss = 0.005333, LR = 1.00e-04\n",
            "\n",
            "Epoch 6/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 Training: 100%|██████████| 67/67 [00:21<00:00,  3.15it/s, Loss=0.000569, Avg Loss=0.001282]\n",
            "Epoch 6 Validation: 100%|██████████| 17/17 [00:01<00:00,  9.82it/s, Val Loss=0.000667, Avg Val Loss=0.003719]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: results/best_model.pth\n",
            "Epoch 6: Train Loss = 0.001282, Val Loss = 0.003719, LR = 1.00e-04\n",
            "\n",
            "Epoch 7/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 Training: 100%|██████████| 67/67 [00:22<00:00,  2.97it/s, Loss=0.001374, Avg Loss=0.001093]\n",
            "Epoch 7 Validation: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, Val Loss=0.001377, Avg Val Loss=0.003056]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: results/best_model.pth\n",
            "Epoch 7: Train Loss = 0.001093, Val Loss = 0.003056, LR = 1.00e-04\n",
            "\n",
            "Epoch 8/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 Training: 100%|██████████| 67/67 [00:22<00:00,  2.95it/s, Loss=0.000668, Avg Loss=0.001147]\n",
            "Epoch 8 Validation: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, Val Loss=0.003698, Avg Val Loss=0.002809]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: results/best_model.pth\n",
            "Epoch 8: Train Loss = 0.001147, Val Loss = 0.002809, LR = 1.00e-04\n",
            "\n",
            "Epoch 9/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 Training: 100%|██████████| 67/67 [00:22<00:00,  2.94it/s, Loss=0.000821, Avg Loss=0.001031]\n",
            "Epoch 9 Validation: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, Val Loss=0.001262, Avg Val Loss=0.002690]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: results/best_model.pth\n",
            "Epoch 9: Train Loss = 0.001031, Val Loss = 0.002690, LR = 1.00e-04\n",
            "\n",
            "Epoch 10/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 Training: 100%|██████████| 67/67 [00:25<00:00,  2.65it/s, Loss=0.000795, Avg Loss=0.000936]\n",
            "Epoch 10 Validation: 100%|██████████| 17/17 [00:01<00:00,  9.42it/s, Val Loss=0.001244, Avg Val Loss=0.002800]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train Loss = 0.000936, Val Loss = 0.002800, LR = 1.00e-04\n",
            "\n",
            "Epoch 11/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 Training: 100%|██████████| 67/67 [00:22<00:00,  2.92it/s, Loss=0.000515, Avg Loss=0.000906]\n",
            "Epoch 11 Validation: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, Val Loss=0.000915, Avg Val Loss=0.001725]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: results/best_model.pth\n",
            "Epoch 11: Train Loss = 0.000906, Val Loss = 0.001725, LR = 1.00e-04\n",
            "\n",
            "Epoch 12/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 Training: 100%|██████████| 67/67 [00:22<00:00,  2.95it/s, Loss=0.000832, Avg Loss=0.000785]\n",
            "Epoch 12 Validation: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, Val Loss=0.002603, Avg Val Loss=0.001811]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: Train Loss = 0.000785, Val Loss = 0.001811, LR = 1.00e-04\n",
            "\n",
            "Epoch 13/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 Training: 100%|██████████| 67/67 [00:22<00:00,  2.99it/s, Loss=0.000611, Avg Loss=0.000742]\n",
            "Epoch 13 Validation: 100%|██████████| 17/17 [00:02<00:00,  7.54it/s, Val Loss=0.003691, Avg Val Loss=0.002326]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Train Loss = 0.000742, Val Loss = 0.002326, LR = 1.00e-04\n",
            "\n",
            "Epoch 14/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 Training: 100%|██████████| 67/67 [00:21<00:00,  3.09it/s, Loss=0.000704, Avg Loss=0.000704]\n",
            "Epoch 14 Validation: 100%|██████████| 17/17 [00:02<00:00,  6.79it/s, Val Loss=0.008058, Avg Val Loss=0.002152]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Train Loss = 0.000704, Val Loss = 0.002152, LR = 1.00e-04\n",
            "\n",
            "Epoch 15/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 Training: 100%|██████████| 67/67 [00:22<00:00,  3.00it/s, Loss=0.000701, Avg Loss=0.000718]\n",
            "Epoch 15 Validation: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, Val Loss=0.001208, Avg Val Loss=0.001826]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Train Loss = 0.000718, Val Loss = 0.001826, LR = 1.00e-04\n",
            "\n",
            "Epoch 16/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 Training: 100%|██████████| 67/67 [00:22<00:00,  2.94it/s, Loss=0.000510, Avg Loss=0.000698]\n",
            "Epoch 16 Validation: 100%|██████████| 17/17 [00:01<00:00,  9.76it/s, Val Loss=0.003908, Avg Val Loss=0.001812]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: Train Loss = 0.000698, Val Loss = 0.001812, LR = 1.00e-04\n",
            "\n",
            "Epoch 17/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 Training: 100%|██████████| 67/67 [00:22<00:00,  2.93it/s, Loss=0.000675, Avg Loss=0.000641]\n",
            "Epoch 17 Validation: 100%|██████████| 17/17 [00:01<00:00,  9.79it/s, Val Loss=0.004914, Avg Val Loss=0.001272]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: results/best_model.pth\n",
            "Epoch 17: Train Loss = 0.000641, Val Loss = 0.001272, LR = 1.00e-04\n",
            "\n",
            "Epoch 18/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 Training: 100%|██████████| 67/67 [00:22<00:00,  2.95it/s, Loss=0.000558, Avg Loss=0.000636]\n",
            "Epoch 18 Validation: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, Val Loss=0.004085, Avg Val Loss=0.001756]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: Train Loss = 0.000636, Val Loss = 0.001756, LR = 1.00e-04\n",
            "\n",
            "Epoch 19/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 Training: 100%|██████████| 67/67 [00:22<00:00,  2.94it/s, Loss=0.000732, Avg Loss=0.000651]\n",
            "Epoch 19 Validation: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, Val Loss=0.005045, Avg Val Loss=0.001554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: Train Loss = 0.000651, Val Loss = 0.001554, LR = 1.00e-04\n",
            "\n",
            "Epoch 20/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 Training: 100%|██████████| 67/67 [00:22<00:00,  3.02it/s, Loss=0.000574, Avg Loss=0.000623]\n",
            "Epoch 20 Validation: 100%|██████████| 17/17 [00:02<00:00,  7.59it/s, Val Loss=0.003757, Avg Val Loss=0.001651]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: Train Loss = 0.000623, Val Loss = 0.001651, LR = 1.00e-04\n",
            "\n",
            "Epoch 21/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 Training: 100%|██████████| 67/67 [00:21<00:00,  3.09it/s, Loss=0.000657, Avg Loss=0.000615]\n",
            "Epoch 21 Validation: 100%|██████████| 17/17 [00:02<00:00,  7.03it/s, Val Loss=0.003861, Avg Val Loss=0.001658]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21: Train Loss = 0.000615, Val Loss = 0.001658, LR = 1.00e-04\n",
            "\n",
            "Epoch 22/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22 Training: 100%|██████████| 67/67 [00:21<00:00,  3.07it/s, Loss=0.000684, Avg Loss=0.000613]\n",
            "Epoch 22 Validation: 100%|██████████| 17/17 [00:01<00:00,  9.28it/s, Val Loss=0.001738, Avg Val Loss=0.001375]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22: Train Loss = 0.000613, Val Loss = 0.001375, LR = 1.00e-04\n",
            "\n",
            "Epoch 23/33\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23 Training:  76%|███████▌  | 51/67 [00:18<00:05,  2.77it/s, Loss=0.000622, Avg Loss=0.000612]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-632783599.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;31m# Запуск обучения\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-632783599.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;31m# Обучение\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-632783599.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, criterion, optimizer, device, epoch)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"final_model.pth\")"
      ],
      "metadata": {
        "id": "46o5BEupzSoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    \"\"\"Датасет для тестовых изображений\"\"\"\n",
        "\n",
        "    def __init__(self, csv_path, images_dir, img_size=224):\n",
        "        self.csv_path = Path(csv_path)\n",
        "        self.images_dir = Path(images_dir)\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # Загрузка CSV файла\n",
        "        self.df = pd.read_csv(self.csv_path)\n",
        "        print(f\"Loaded test CSV: {len(self.df)} samples\")\n",
        "        print(f\"Columns: {list(self.df.columns)}\")\n",
        "\n",
        "        # Параметры нормализации (должны совпадать с тренировочными)\n",
        "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def _read_image(self, image_path):\n",
        "        \"\"\"Чтение и предобработка изображения\"\"\"\n",
        "        try:\n",
        "            img = cv2.imread(str(image_path), cv2.IMREAD_UNCHANGED)\n",
        "            if img is None:\n",
        "                img = cv2.imread(str(image_path), cv2.IMREAD_COLOR)\n",
        "\n",
        "            if img is None:\n",
        "                raise ValueError(f\"Cannot read image: {image_path}\")\n",
        "\n",
        "            # Конвертируем в float и нормализуем\n",
        "            if img.dtype == np.uint16:\n",
        "                img = img.astype(np.float32) / 65535.0\n",
        "            elif img.dtype == np.uint8:\n",
        "                img = img.astype(np.float32) / 255.0\n",
        "\n",
        "            # BGR to RGB\n",
        "            if img.shape[-1] == 3:\n",
        "                img = img[..., ::-1]\n",
        "\n",
        "            # Resize\n",
        "            if img.shape[0] != self.img_size or img.shape[1] != self.img_size:\n",
        "                img = cv2.resize(img, (self.img_size, self.img_size))\n",
        "\n",
        "            return img\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading image {image_path}: {e}\")\n",
        "            return np.ones((self.img_size, self.img_size, 3), dtype=np.float32) * 0.5\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            row = self.df.iloc[idx]\n",
        "\n",
        "            # Получаем путь к изображению (предполагаем, что первый столбец)\n",
        "            image_path_str = row.iloc[0]  # Первая колонка содержит пути\n",
        "            if pd.isna(image_path_str):\n",
        "                image_path_str = f\"test_image_{idx:04d}.png\"\n",
        "\n",
        "            # Создаем полный путь\n",
        "            image_path = self.images_dir / image_path_str\n",
        "\n",
        "            # Чтение изображения\n",
        "            image = self._read_image(image_path)\n",
        "\n",
        "            # Преобразование в tensor и нормализация\n",
        "            image_tensor = torch.from_numpy(image.transpose(2, 0, 1)).float()\n",
        "            image_tensor = (image_tensor - self.mean) / self.std\n",
        "\n",
        "            return image_tensor, str(image_path_str)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading sample {idx}: {e}\")\n",
        "            # Возвращаем dummy данные\n",
        "            dummy_image = torch.randn(3, self.img_size, self.img_size)\n",
        "            return dummy_image, f\"error_{idx}.png\"\n",
        "\n",
        "class WhiteBalanceModel(nn.Module):\n",
        "    \"\"\"Модель для предсказания точки белого\"\"\"\n",
        "\n",
        "    def __init__(self, pretrained=False):\n",
        "        super(WhiteBalanceModel, self).__init__()\n",
        "\n",
        "        # Базовая архитектура (должна совпадать с обученной моделью)\n",
        "        from torchvision.models import efficientnet_b0\n",
        "\n",
        "        if pretrained:\n",
        "            from torchvision.models import EfficientNet_B0_Weights\n",
        "            self.backbone = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "        else:\n",
        "            self.backbone = efficientnet_b0(weights=None)\n",
        "\n",
        "        # Заменяем классификатор\n",
        "        in_features = self.backbone.classifier[1].in_features\n",
        "        self.backbone.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.3),\n",
        "            nn.Linear(in_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 3),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "def load_model(model_path, device, pretrained=False):\n",
        "    \"\"\"Загрузка обученной модели\"\"\"\n",
        "    print(f\"Loading model from: {model_path}\")\n",
        "\n",
        "    model = WhiteBalanceModel(pretrained=pretrained).to(device)\n",
        "\n",
        "    if os.path.exists(model_path):\n",
        "        try:\n",
        "            # Пробуем загрузить полный checkpoint или только веса\n",
        "            checkpoint = torch.load(model_path, map_location=device)\n",
        "\n",
        "            if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
        "                model.load_state_dict(checkpoint['model_state_dict'])\n",
        "                print(\"Loaded from checkpoint\")\n",
        "            else:\n",
        "                model.load_state_dict(checkpoint)\n",
        "                print(\"Loaded model weights\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model: {e}\")\n",
        "            print(\"Using randomly initialized model\")\n",
        "    else:\n",
        "        print(f\"Model file not found: {model_path}\")\n",
        "        print(\"Using randomly initialized model\")\n",
        "\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def create_predictions(model, test_loader, device):\n",
        "    \"\"\"Создание предсказаний для тестового набора\"\"\"\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_image_paths = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, image_paths in tqdm(test_loader, desc=\"Making predictions\"):\n",
        "            images = images.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Денормализуем предсказания из [0, 1] в [0, 65535]\n",
        "            predictions = outputs.cpu().numpy() * 65535.0\n",
        "\n",
        "            all_predictions.extend(predictions)\n",
        "            all_image_paths.extend(image_paths)\n",
        "\n",
        "    return all_image_paths, all_predictions\n",
        "\n",
        "def create_submission_file(image_paths, predictions, output_csv=\"submission.csv\"):\n",
        "    \"\"\"Создание submission файла в правильном формате\"\"\"\n",
        "    print(f\"Creating submission file: {output_csv}\")\n",
        "\n",
        "    data = []\n",
        "    for img_path, pred in zip(image_paths, predictions):\n",
        "        try:\n",
        "            # Извлекаем только имя файла (без пути)\n",
        "            if isinstance(img_path, str):\n",
        "                filename = Path(img_path).name\n",
        "            else:\n",
        "                filename = f\"image_{len(data):04d}.png\"\n",
        "\n",
        "            # Обеспечиваем корректный диапазон значений [0, 65535]\n",
        "            wp_r = float(np.clip(pred[0], 0, 65535))\n",
        "            wp_g = float(np.clip(pred[1], 0, 65535))\n",
        "            wp_b = float(np.clip(pred[2], 0, 65535))\n",
        "\n",
        "            data.append({\n",
        "                'image_path': filename,\n",
        "                'wp_r': wp_r,\n",
        "                'wp_g': wp_g,\n",
        "                'wp_b': wp_b\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_path}: {e}\")\n",
        "            # Добавляем значения по умолчанию\n",
        "            data.append({\n",
        "                'image_path': f\"error_{len(data):04d}.png\",\n",
        "                'wp_r': 32768.0,\n",
        "                'wp_g': 32768.0,\n",
        "                'wp_b': 32768.0\n",
        "            })\n",
        "\n",
        "    # Создаем DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Сохраняем CSV\n",
        "    df.to_csv(output_csv, index=False, float_format='%.6f')\n",
        "\n",
        "    print(f\"Submission file created with {len(df)} predictions\")\n",
        "    print(\"First 5 predictions:\")\n",
        "    print(df.head())\n",
        "\n",
        "    return df\n",
        "\n",
        "def main():\n",
        "    \"\"\"Основная функция для создания предсказаний\"\"\"\n",
        "\n",
        "    # Пути к данным\n",
        "    TEST_CSV_PATH = \"/content/test.csv\"\n",
        "    TEST_IMAGES_DIR = \"/content/test_imgs2\"\n",
        "    MODEL_PATH = \"/content/final_model.pth\"\n",
        "    OUTPUT_CSV = \"/content/final_submission.csv\"\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"🔄 CREATING PREDICTIONS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Проверка файлов\n",
        "    print(\"🔍 Checking files...\")\n",
        "    print(f\"Test CSV: {TEST_CSV_PATH} → {'✅' if os.path.exists(TEST_CSV_PATH) else '❌'}\")\n",
        "    print(f\"Test images: {TEST_IMAGES_DIR} → {'✅' if os.path.exists(TEST_IMAGES_DIR) else '❌'}\")\n",
        "    print(f\"Model: {MODEL_PATH} → {'✅' if os.path.exists(MODEL_PATH) else '❌'}\")\n",
        "\n",
        "    if not os.path.exists(TEST_CSV_PATH):\n",
        "        print(\"❌ Test CSV not found!\")\n",
        "        return\n",
        "\n",
        "    # Устройство\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"🖥️  Device: {device}\")\n",
        "\n",
        "    # Создаем тестовый датасет\n",
        "    print(\"\\n📁 Creating test dataset...\")\n",
        "    try:\n",
        "        test_dataset = TestDataset(TEST_CSV_PATH, TEST_IMAGES_DIR)\n",
        "        print(f\"✅ Test dataset created: {len(test_dataset)} samples\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error creating dataset: {e}\")\n",
        "        return\n",
        "\n",
        "    # DataLoader\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=8,\n",
        "        shuffle=False,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    # Загрузка модели\n",
        "    print(\"\\n🤖 Loading model...\")\n",
        "    model = load_model(MODEL_PATH, device, pretrained=False)\n",
        "\n",
        "    # Создание предсказаний\n",
        "    print(\"\\n🎯 Making predictions...\")\n",
        "    image_paths, predictions = create_predictions(model, test_loader, device)\n",
        "\n",
        "    # Создание submission файла\n",
        "    print(\"\\n💾 Creating submission file...\")\n",
        "    submission_df = create_submission_file(image_paths, predictions, OUTPUT_CSV)\n",
        "\n",
        "    # Статистика\n",
        "    print(\"\\n📊 Prediction statistics:\")\n",
        "    pred_array = np.array(predictions)\n",
        "    print(f\"Total predictions: {len(predictions)}\")\n",
        "    print(f\"Value ranges:\")\n",
        "    print(f\"  R: {pred_array[:, 0].min():.1f} - {pred_array[:, 0].max():.1f}\")\n",
        "    print(f\"  G: {pred_array[:, 1].min():.1f} - {pred_array[:, 1].max():.1f}\")\n",
        "    print(f\"  B: {pred_array[:, 2].min():.1f} - {pred_array[:, 2].max():.1f}\")\n",
        "\n",
        "    # Проверка корректности значений\n",
        "    valid_mask = np.all((pred_array >= 0) & (pred_array <= 65535), axis=1)\n",
        "    invalid_count = np.sum(~valid_mask)\n",
        "\n",
        "    if invalid_count > 0:\n",
        "        print(f\"⚠️  Warning: {invalid_count} predictions outside valid range [0, 65535]\")\n",
        "    else:\n",
        "        print(\"✅ All predictions are within valid range\")\n",
        "\n",
        "    print(f\"\\n🎉 Done! Submission file saved to: {OUTPUT_CSV}\")\n",
        "\n",
        "# Альтернативная простая версия\n",
        "def quick_predict():\n",
        "    \"\"\"Быстрое создание предсказаний\"\"\"\n",
        "\n",
        "    # Пути по умолчанию\n",
        "    paths = {\n",
        "        'test_csv': '/content/test (3).csv',\n",
        "        'test_images': '/content/test_imgs',\n",
        "        'model': '/content/final_model.pth',\n",
        "        'output': '/content/submission (1).csv'\n",
        "    }\n",
        "\n",
        "    # Проверяем существование файлов\n",
        "    for name, path in paths.items():\n",
        "        if not os.path.exists(path) and name != 'output':\n",
        "            print(f\"❌ File not found: {path}\")\n",
        "            return\n",
        "\n",
        "    # Запускаем основной процесс\n",
        "    main()\n",
        "\n",
        "# Утилиты для проверки\n",
        "def check_submission_format():\n",
        "    \"\"\"Проверяет формат submission файла\"\"\"\n",
        "    try:\n",
        "        # Пример правильного формата\n",
        "        example_data = {\n",
        "            'image_path': ['test1.png', 'test2.png'],\n",
        "            'wp_r': [30000.0, 32000.0],\n",
        "            'wp_g': [31000.0, 33000.0],\n",
        "            'wp_b': [29000.0, 28000.0]\n",
        "        }\n",
        "\n",
        "        example_df = pd.DataFrame(example_data)\n",
        "        print(\"📋 Example submission format:\")\n",
        "        print(example_df)\n",
        "        print(\"\\n✅ Columns should be: image_path, wp_r, wp_g, wp_b\")\n",
        "        print(\"✅ Values should be in range [0, 65535]\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Показываем пример формата\n",
        "    check_submission_format()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    # Запускаем создание предсказаний\n",
        "    main()\n",
        "\n",
        "    # Или быстрый запуск\n",
        "    # quick_predict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWLuljwXhl7W",
        "outputId": "b6f693b5-79d4-4a08-91c3-67a2f42e7e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📋 Example submission format:\n",
            "  image_path     wp_r     wp_g     wp_b\n",
            "0  test1.png  30000.0  31000.0  29000.0\n",
            "1  test2.png  32000.0  33000.0  28000.0\n",
            "\n",
            "✅ Columns should be: image_path, wp_r, wp_g, wp_b\n",
            "✅ Values should be in range [0, 65535]\n",
            "\n",
            "============================================================\n",
            "============================================================\n",
            "🔄 CREATING PREDICTIONS\n",
            "============================================================\n",
            "🔍 Checking files...\n",
            "Test CSV: /content/test.csv → ✅\n",
            "Test images: /content/test_imgs2 → ❌\n",
            "Model: /content/final_model.pth → ✅\n",
            "🖥️  Device: cpu\n",
            "\n",
            "📁 Creating test dataset...\n",
            "Loaded test CSV: 145 samples\n",
            "Columns: ['names']\n",
            "✅ Test dataset created: 145 samples\n",
            "\n",
            "🤖 Loading model...\n",
            "Loading model from: /content/final_model.pth\n",
            "Loaded model weights\n",
            "\n",
            "🎯 Making predictions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:   0%|          | 0/19 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0001.png: Cannot read image: /content/test_imgs2/test_imgs/0001.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0015.png: Cannot read image: /content/test_imgs2/test_imgs/0015.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0034.png: Cannot read image: /content/test_imgs2/test_imgs/0034.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0018.png: Cannot read image: /content/test_imgs2/test_imgs/0018.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0035.png: Cannot read image: /content/test_imgs2/test_imgs/0035.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0019.png: Cannot read image: /content/test_imgs2/test_imgs/0019.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0042.png: Cannot read image: /content/test_imgs2/test_imgs/0042.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0020.png: Cannot read image: /content/test_imgs2/test_imgs/0020.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0049.png: Cannot read image: /content/test_imgs2/test_imgs/0049.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0055.png: Cannot read image: /content/test_imgs2/test_imgs/0055.pngError reading image /content/test_imgs2/test_imgs/0022.png: Cannot read image: /content/test_imgs2/test_imgs/0022.png\n",
            "\n",
            "Error reading image /content/test_imgs2/test_imgs/0061.png: Cannot read image: /content/test_imgs2/test_imgs/0061.pngError reading image /content/test_imgs2/test_imgs/0027.png: Cannot read image: /content/test_imgs2/test_imgs/0027.png\n",
            "\n",
            "Error reading image /content/test_imgs2/test_imgs/0062.png: Cannot read image: /content/test_imgs2/test_imgs/0062.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0030.png: Cannot read image: /content/test_imgs2/test_imgs/0030.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0083.png: Cannot read image: /content/test_imgs2/test_imgs/0083.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0087.png: Cannot read image: /content/test_imgs2/test_imgs/0087.pngError reading image /content/test_imgs2/test_imgs/0133.png: Cannot read image: /content/test_imgs2/test_imgs/0133.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0134.png: Cannot read image: /content/test_imgs2/test_imgs/0134.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0091.png: Cannot read image: /content/test_imgs2/test_imgs/0091.png\n",
            "\n",
            "Error reading image /content/test_imgs2/test_imgs/0094.png: Cannot read image: /content/test_imgs2/test_imgs/0094.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0095.png: Cannot read image: /content/test_imgs2/test_imgs/0095.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0150.png: Cannot read image: /content/test_imgs2/test_imgs/0150.pngError reading image /content/test_imgs2/test_imgs/0100.png: Cannot read image: /content/test_imgs2/test_imgs/0100.png\n",
            "\n",
            "Error reading image /content/test_imgs2/test_imgs/0126.png: Cannot read image: /content/test_imgs2/test_imgs/0126.pngError reading image /content/test_imgs2/test_imgs/0154.png: Cannot read image: /content/test_imgs2/test_imgs/0154.png\n",
            "\n",
            "Error reading image /content/test_imgs2/test_imgs/0169.png: Cannot read image: /content/test_imgs2/test_imgs/0169.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0175.png: Cannot read image: /content/test_imgs2/test_imgs/0175.pngError reading image /content/test_imgs2/test_imgs/0127.png: Cannot read image: /content/test_imgs2/test_imgs/0127.png\n",
            "\n",
            "Error reading image /content/test_imgs2/test_imgs/0179.png: Cannot read image: /content/test_imgs2/test_imgs/0179.pngError reading image /content/test_imgs2/test_imgs/0132.png: Cannot read image: /content/test_imgs2/test_imgs/0132.png\n",
            "\n",
            "Error reading image /content/test_imgs2/test_imgs/0182.png: Cannot read image: /content/test_imgs2/test_imgs/0182.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0186.png: Cannot read image: /content/test_imgs2/test_imgs/0186.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0187.png: Cannot read image: /content/test_imgs2/test_imgs/0187.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0192.png: Cannot read image: /content/test_imgs2/test_imgs/0192.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0199.png: Cannot read image: /content/test_imgs2/test_imgs/0199.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0208.png: Cannot read image: /content/test_imgs2/test_imgs/0208.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0222.png: Cannot read image: /content/test_imgs2/test_imgs/0222.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0228.png: Cannot read image: /content/test_imgs2/test_imgs/0228.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0234.png: Cannot read image: /content/test_imgs2/test_imgs/0234.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:   5%|▌         | 1/19 [00:01<00:19,  1.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0238.png: Cannot read image: /content/test_imgs2/test_imgs/0238.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0239.png: Cannot read image: /content/test_imgs2/test_imgs/0239.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0241.png: Cannot read image: /content/test_imgs2/test_imgs/0241.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0242.png: Cannot read image: /content/test_imgs2/test_imgs/0242.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0243.png: Cannot read image: /content/test_imgs2/test_imgs/0243.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0245.png: Cannot read image: /content/test_imgs2/test_imgs/0245.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0264.png: Cannot read image: /content/test_imgs2/test_imgs/0264.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0291.png: Cannot read image: /content/test_imgs2/test_imgs/0291.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  11%|█         | 2/19 [00:01<00:15,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0297.png: Cannot read image: /content/test_imgs2/test_imgs/0297.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0312.png: Cannot read image: /content/test_imgs2/test_imgs/0312.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0313.png: Cannot read image: /content/test_imgs2/test_imgs/0313.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0317.png: Cannot read image: /content/test_imgs2/test_imgs/0317.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0319.png: Cannot read image: /content/test_imgs2/test_imgs/0319.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0334.png: Cannot read image: /content/test_imgs2/test_imgs/0334.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0341.png: Cannot read image: /content/test_imgs2/test_imgs/0341.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0348.png: Cannot read image: /content/test_imgs2/test_imgs/0348.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  16%|█▌        | 3/19 [00:02<00:13,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0351.png: Cannot read image: /content/test_imgs2/test_imgs/0351.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0355.png: Cannot read image: /content/test_imgs2/test_imgs/0355.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0357.png: Cannot read image: /content/test_imgs2/test_imgs/0357.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0358.png: Cannot read image: /content/test_imgs2/test_imgs/0358.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0359.png: Cannot read image: /content/test_imgs2/test_imgs/0359.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0373.png: Cannot read image: /content/test_imgs2/test_imgs/0373.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0376.png: Cannot read image: /content/test_imgs2/test_imgs/0376.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0377.png: Cannot read image: /content/test_imgs2/test_imgs/0377.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  21%|██        | 4/19 [00:03<00:12,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0379.png: Cannot read image: /content/test_imgs2/test_imgs/0379.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0380.png: Cannot read image: /content/test_imgs2/test_imgs/0380.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0385.png: Cannot read image: /content/test_imgs2/test_imgs/0385.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0396.png: Cannot read image: /content/test_imgs2/test_imgs/0396.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0401.png: Cannot read image: /content/test_imgs2/test_imgs/0401.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0407.png: Cannot read image: /content/test_imgs2/test_imgs/0407.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0411.png: Cannot read image: /content/test_imgs2/test_imgs/0411.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0416.png: Cannot read image: /content/test_imgs2/test_imgs/0416.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  26%|██▋       | 5/19 [00:04<00:11,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0443.png: Cannot read image: /content/test_imgs2/test_imgs/0443.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0456.png: Cannot read image: /content/test_imgs2/test_imgs/0456.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0464.png: Cannot read image: /content/test_imgs2/test_imgs/0464.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0470.png: Cannot read image: /content/test_imgs2/test_imgs/0470.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0479.png: Cannot read image: /content/test_imgs2/test_imgs/0479.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0486.png: Cannot read image: /content/test_imgs2/test_imgs/0486.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0496.png: Cannot read image: /content/test_imgs2/test_imgs/0496.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0500.png: Cannot read image: /content/test_imgs2/test_imgs/0500.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  32%|███▏      | 6/19 [00:04<00:09,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0513.png: Cannot read image: /content/test_imgs2/test_imgs/0513.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0528.png: Cannot read image: /content/test_imgs2/test_imgs/0528.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0534.png: Cannot read image: /content/test_imgs2/test_imgs/0534.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0558.png: Cannot read image: /content/test_imgs2/test_imgs/0558.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0570.png: Cannot read image: /content/test_imgs2/test_imgs/0570.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0574.png: Cannot read image: /content/test_imgs2/test_imgs/0574.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0589.png: Cannot read image: /content/test_imgs2/test_imgs/0589.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0592.png: Cannot read image: /content/test_imgs2/test_imgs/0592.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  37%|███▋      | 7/19 [00:05<00:08,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0596.png: Cannot read image: /content/test_imgs2/test_imgs/0596.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0600.png: Cannot read image: /content/test_imgs2/test_imgs/0600.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0601.png: Cannot read image: /content/test_imgs2/test_imgs/0601.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0604.png: Cannot read image: /content/test_imgs2/test_imgs/0604.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0609.png: Cannot read image: /content/test_imgs2/test_imgs/0609.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0614.png: Cannot read image: /content/test_imgs2/test_imgs/0614.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0616.png: Cannot read image: /content/test_imgs2/test_imgs/0616.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0627.png: Cannot read image: /content/test_imgs2/test_imgs/0627.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  42%|████▏     | 8/19 [00:05<00:07,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0634.png: Cannot read image: /content/test_imgs2/test_imgs/0634.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0644.png: Cannot read image: /content/test_imgs2/test_imgs/0644.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0647.png: Cannot read image: /content/test_imgs2/test_imgs/0647.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0649.png: Cannot read image: /content/test_imgs2/test_imgs/0649.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0661.png: Cannot read image: /content/test_imgs2/test_imgs/0661.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0665.png: Cannot read image: /content/test_imgs2/test_imgs/0665.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0669.png: Cannot read image: /content/test_imgs2/test_imgs/0669.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0677.png: Cannot read image: /content/test_imgs2/test_imgs/0677.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  47%|████▋     | 9/19 [00:06<00:06,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0679.png: Cannot read image: /content/test_imgs2/test_imgs/0679.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0682.png: Cannot read image: /content/test_imgs2/test_imgs/0682.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0687.png: Cannot read image: /content/test_imgs2/test_imgs/0687.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0693.png: Cannot read image: /content/test_imgs2/test_imgs/0693.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0700.png: Cannot read image: /content/test_imgs2/test_imgs/0700.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0709.png: Cannot read image: /content/test_imgs2/test_imgs/0709.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0726.png: Cannot read image: /content/test_imgs2/test_imgs/0726.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0727.png: Cannot read image: /content/test_imgs2/test_imgs/0727.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  53%|█████▎    | 10/19 [00:07<00:05,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0752.png: Cannot read image: /content/test_imgs2/test_imgs/0752.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0757.png: Cannot read image: /content/test_imgs2/test_imgs/0757.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0760.png: Cannot read image: /content/test_imgs2/test_imgs/0760.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0763.png: Cannot read image: /content/test_imgs2/test_imgs/0763.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0768.png: Cannot read image: /content/test_imgs2/test_imgs/0768.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0770.png: Cannot read image: /content/test_imgs2/test_imgs/0770.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0774.png: Cannot read image: /content/test_imgs2/test_imgs/0774.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0778.png: Cannot read image: /content/test_imgs2/test_imgs/0778.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  58%|█████▊    | 11/19 [00:07<00:04,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0791.png: Cannot read image: /content/test_imgs2/test_imgs/0791.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0792.png: Cannot read image: /content/test_imgs2/test_imgs/0792.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0799.png: Cannot read image: /content/test_imgs2/test_imgs/0799.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0800.png: Cannot read image: /content/test_imgs2/test_imgs/0800.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0804.png: Cannot read image: /content/test_imgs2/test_imgs/0804.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0806.png: Cannot read image: /content/test_imgs2/test_imgs/0806.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0816.png: Cannot read image: /content/test_imgs2/test_imgs/0816.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0818.png: Cannot read image: /content/test_imgs2/test_imgs/0818.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  63%|██████▎   | 12/19 [00:08<00:04,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0821.png: Cannot read image: /content/test_imgs2/test_imgs/0821.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0823.png: Cannot read image: /content/test_imgs2/test_imgs/0823.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0842.png: Cannot read image: /content/test_imgs2/test_imgs/0842.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0852.png: Cannot read image: /content/test_imgs2/test_imgs/0852.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0855.png: Cannot read image: /content/test_imgs2/test_imgs/0855.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0868.png: Cannot read image: /content/test_imgs2/test_imgs/0868.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0877.png: Cannot read image: /content/test_imgs2/test_imgs/0877.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0883.png: Cannot read image: /content/test_imgs2/test_imgs/0883.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  68%|██████▊   | 13/19 [00:08<00:03,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0890.png: Cannot read image: /content/test_imgs2/test_imgs/0890.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0895.png: Cannot read image: /content/test_imgs2/test_imgs/0895.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0896.png: Cannot read image: /content/test_imgs2/test_imgs/0896.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0909.png: Cannot read image: /content/test_imgs2/test_imgs/0909.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0912.png: Cannot read image: /content/test_imgs2/test_imgs/0912.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0917.png: Cannot read image: /content/test_imgs2/test_imgs/0917.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0924.png: Cannot read image: /content/test_imgs2/test_imgs/0924.png\n",
            "Error reading image /content/test_imgs2/test_imgs/0925.png: Cannot read image: /content/test_imgs2/test_imgs/0925.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rMaking predictions:  74%|███████▎  | 14/19 [00:09<00:02,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading image /content/test_imgs2/test_imgs/0926.png: Cannot read image: /content/test_imgs2/test_imgs/0926.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions: 100%|██████████| 19/19 [00:11<00:00,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "💾 Creating submission file...\n",
            "Creating submission file: /content/final_submission.csv\n",
            "Submission file created with 145 predictions\n",
            "First 5 predictions:\n",
            "  image_path     wp_r  wp_g  wp_b\n",
            "0   0001.png  65535.0   0.0   0.0\n",
            "1   0015.png  65535.0   0.0   0.0\n",
            "2   0018.png  65535.0   0.0   0.0\n",
            "3   0019.png  65535.0   0.0   0.0\n",
            "4   0020.png  65535.0   0.0   0.0\n",
            "\n",
            "📊 Prediction statistics:\n",
            "Total predictions: 145\n",
            "Value ranges:\n",
            "  R: 65535.0 - 65535.0\n",
            "  G: 0.0 - 0.0\n",
            "  B: 0.0 - 0.0\n",
            "✅ All predictions are within valid range\n",
            "\n",
            "🎉 Done! Submission file saved to: /content/final_submission.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def merge_submission_files(submission_path, source_path, output_path):\n",
        "    \"\"\"\n",
        "    Объединяет данные: берет первую колонку из submission файла\n",
        "    и остальные три колонки из source файла\n",
        "\n",
        "    Args:\n",
        "        submission_path: путь к файлу submission.csv (откуда берем image_path)\n",
        "        source_path: путь к исходному файлу (откуда берем wp_r, wp_g, wp_b)\n",
        "        output_path: путь для сохранения результата\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"🔍 Reading files...\")\n",
        "\n",
        "    try:\n",
        "        # Читаем submission файл\n",
        "        submission_df = pd.read_csv(submission_path)\n",
        "        print(f\"✅ Submission file loaded: {len(submission_df)} rows\")\n",
        "        print(f\"   Columns: {list(submission_df.columns)}\")\n",
        "\n",
        "        # Читаем source файл\n",
        "        source_df = pd.read_csv(source_path)\n",
        "        print(f\"✅ Source file loaded: {len(source_df)} rows\")\n",
        "        print(f\"   Columns: {list(source_df.columns)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error reading files: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Проверяем, что файлы имеют одинаковое количество строк\n",
        "    if len(submission_df) != len(source_df):\n",
        "        print(f\"⚠️  Warning: Different number of rows!\")\n",
        "        print(f\"   Submission: {len(submission_df)} rows\")\n",
        "        print(f\"   Source: {len(source_df)} rows\")\n",
        "\n",
        "        # Берем минимальное количество строк\n",
        "        min_rows = min(len(submission_df), len(source_df))\n",
        "        submission_df = submission_df.head(min_rows)\n",
        "        source_df = source_df.head(min_rows)\n",
        "        print(f\"   Using first {min_rows} rows from each file\")\n",
        "\n",
        "    # Проверяем наличие нужных колонок\n",
        "    submission_cols = submission_df.columns\n",
        "    source_cols = source_df.columns\n",
        "\n",
        "    # Определяем колонку с путями из submission файла\n",
        "    if 'image_path' in submission_cols:\n",
        "        image_path_col = 'image_path'\n",
        "    else:\n",
        "        # Берем первую колонку\n",
        "        image_path_col = submission_cols[0]\n",
        "        print(f\"ℹ️  Using first column as image_path: {image_path_col}\")\n",
        "\n",
        "    # Определяем колонки для white balance из source файла\n",
        "    wp_cols = []\n",
        "    for col in ['wp_r', 'wp_g', 'wp_b']:\n",
        "        if col in source_cols:\n",
        "            wp_cols.append(col)\n",
        "        else:\n",
        "            # Ищем альтернативные названия\n",
        "            for source_col in source_cols:\n",
        "                if col in source_col.lower() or 'white' in source_col.lower():\n",
        "                    wp_cols.append(source_col)\n",
        "                    print(f\"ℹ️  Using {source_col} as {col}\")\n",
        "                    break\n",
        "            else:\n",
        "                # Если не нашли, берем первые три колонки после image_path\n",
        "                if len(source_cols) >= 4:\n",
        "                    wp_cols.extend(source_cols[1:4])\n",
        "                else:\n",
        "                    wp_cols.extend(source_cols[:3])\n",
        "                print(f\"ℹ️  Using columns {wp_cols} for white balance values\")\n",
        "                break\n",
        "\n",
        "    # Ограничиваем до 3 колонок\n",
        "    wp_cols = wp_cols[:3]\n",
        "\n",
        "    # Создаем новый DataFrame\n",
        "    print(\"\\n🔄 Merging data...\")\n",
        "\n",
        "    try:\n",
        "        # Берем image_path из submission файла\n",
        "        result_df = pd.DataFrame()\n",
        "        result_df['image_path'] = submission_df[image_path_col]\n",
        "\n",
        "        # Берем white balance значения из source файла\n",
        "        for i, col in enumerate(wp_cols[:3]):  # Берем максимум 3 колонки\n",
        "            if i == 0:\n",
        "                result_df['wp_r'] = source_df[col]\n",
        "            elif i == 1:\n",
        "                result_df['wp_g'] = source_df[col]\n",
        "            elif i == 2:\n",
        "                result_df['wp_b'] = source_df[col]\n",
        "\n",
        "        # Если не хватило колонок, заполняем значениями по умолчанию\n",
        "        if len(wp_cols) < 3:\n",
        "            print(f\"⚠️  Only {len(wp_cols)} white balance columns found\")\n",
        "            if 'wp_r' not in result_df.columns:\n",
        "                result_df['wp_r'] = 32768.0\n",
        "            if 'wp_g' not in result_df.columns:\n",
        "                result_df['wp_g'] = 32768.0\n",
        "            if 'wp_b' not in result_df.columns:\n",
        "                result_df['wp_b'] = 32768.0\n",
        "\n",
        "        # Сохраняем результат\n",
        "        result_df.to_csv(output_path, index=False, float_format='%.6f')\n",
        "\n",
        "        print(f\"✅ Merged file saved: {output_path}\")\n",
        "        print(f\"📊 Result shape: {result_df.shape}\")\n",
        "        print(f\"📋 Columns: {list(result_df.columns)}\")\n",
        "        print(\"\\n📄 First 5 rows:\")\n",
        "        print(result_df.head())\n",
        "\n",
        "        return result_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error merging files: {e}\")\n",
        "        return None\n",
        "\n",
        "def create_manual_merge(submission_path, source_path, output_path):\n",
        "    \"\"\"\n",
        "    Ручное объединение с выбором колонок\n",
        "    \"\"\"\n",
        "    print(\"📝 Manual merge mode\")\n",
        "\n",
        "    # Читаем файлы\n",
        "    submission_df = pd.read_csv(submission_path)\n",
        "    source_df = pd.read_csv(source_path)\n",
        "\n",
        "    print(f\"Submission file columns: {list(submission_df.columns)}\")\n",
        "    print(f\"Source file columns: {list(source_df.columns)}\")\n",
        "\n",
        "    # Создаем новый DataFrame\n",
        "    result_df = pd.DataFrame()\n",
        "\n",
        "    # Выбираем колонку для image_path\n",
        "    image_col = input(\"Enter column name for image_path from submission file: \").strip()\n",
        "    if image_col not in submission_df.columns:\n",
        "        print(f\"Column '{image_col}' not found, using first column\")\n",
        "        image_col = submission_df.columns[0]\n",
        "\n",
        "    result_df['image_path'] = submission_df[image_col]\n",
        "\n",
        "    # Выбираем колонки для white balance\n",
        "    wp_mapping = {}\n",
        "    for wp_col in ['wp_r', 'wp_g', 'wp_b']:\n",
        "        col_name = input(f\"Enter column name for {wp_col} from source file: \").strip()\n",
        "        if col_name in source_df.columns:\n",
        "            result_df[wp_col] = source_df[col_name]\n",
        "            wp_mapping[wp_col] = col_name\n",
        "        else:\n",
        "            print(f\"Column '{col_name}' not found, using default value 32768.0\")\n",
        "            result_df[wp_col] = 32768.0\n",
        "\n",
        "    # Сохраняем\n",
        "    result_df.to_csv(output_path, index=False, float_format='%.6f')\n",
        "    print(f\"✅ Manual merge saved to: {output_path}\")\n",
        "\n",
        "    return result_df\n",
        "\n",
        "def quick_merge():\n",
        "    \"\"\"\n",
        "    Быстрое объединение с стандартными путями\n",
        "    \"\"\"\n",
        "    submission_file = \"/content/submission.csv\"\n",
        "    source_file = \"/content/submission.csv\"  # или ваш файл с white balance значениями\n",
        "    output_file = \"/content/merged_submission.csv\"\n",
        "\n",
        "    print(\"🚀 Quick merge with default paths:\")\n",
        "    print(f\"Submission: {submission_file}\")\n",
        "    print(f\"Source: {source_file}\")\n",
        "    print(f\"Output: {output_file}\")\n",
        "\n",
        "    return merge_submission_files(submission_file, source_file, output_file)\n",
        "\n",
        "# Дополнительные утилиты\n",
        "def check_file_info(file_path):\n",
        "    \"\"\"Проверка информации о файле\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        print(f\"📁 File: {file_path}\")\n",
        "        print(f\"📊 Shape: {df.shape}\")\n",
        "        print(f\"📋 Columns: {list(df.columns)}\")\n",
        "        print(f\"🔢 Dtypes:\\n{df.dtypes}\")\n",
        "        print(\"\\n📄 First 3 rows:\")\n",
        "        print(df.head(3))\n",
        "        print(\"\\n📄 Last 3 rows:\")\n",
        "        print(df.tail(3))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error reading {file_path}: {e}\")\n",
        "\n",
        "def compare_files(file1_path, file2_path):\n",
        "    \"\"\"Сравнение двух файлов\"\"\"\n",
        "    df1 = pd.read_csv(file1_path)\n",
        "    df2 = pd.read_csv(file2_path)\n",
        "\n",
        "    print(\"📊 File Comparison:\")\n",
        "    print(f\"File 1: {file1_path} - {df1.shape}\")\n",
        "    print(f\"File 2: {file2_path} - {df2.shape}\")\n",
        "\n",
        "    print(\"\\n📋 Columns comparison:\")\n",
        "    print(f\"File 1 columns: {list(df1.columns)}\")\n",
        "    print(f\"File 2 columns: {list(df2.columns)}\")\n",
        "\n",
        "    common_cols = set(df1.columns) & set(df2.columns)\n",
        "    print(f\"Common columns: {common_cols}\")\n",
        "\n",
        "# Основная функция\n",
        "def main():\n",
        "    \"\"\"Основная функция для запуска в Colab\"\"\"\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"📊 SUBISSION FILE MERGER\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Стандартные пути для Colab\n",
        "    files_to_check = [\n",
        "        \"/content/submission.csv\",\n",
        "        \"/content/you1.csv\",\n",
        "        \"/content/train.csv\"\n",
        "    ]\n",
        "\n",
        "    print(\"🔍 Checking available files:\")\n",
        "    for file_path in files_to_check:\n",
        "        exists = Path(file_path).exists()\n",
        "        status = \"✅\" if exists else \"❌\"\n",
        "        print(f\"{status} {file_path}\")\n",
        "\n",
        "    # Автоматический поиск source файла\n",
        "    source_candidates = [\n",
        "        \"/content/you1.csv\",\n",
        "        \"/content/train.csv\",\n",
        "        \"/content/test.csv\",\n",
        "        \"/content/data.csv\"\n",
        "    ]\n",
        "\n",
        "    source_file = None\n",
        "    for candidate in source_candidates:\n",
        "        if Path(candidate).exists():\n",
        "            source_file = candidate\n",
        "            break\n",
        "\n",
        "    if source_file:\n",
        "        print(f\"\\n🎯 Found source file: {source_file}\")\n",
        "\n",
        "        # Запускаем автоматическое объединение\n",
        "        result = merge_submission_files(\n",
        "            submission_path=\"/content/submission.csv\",\n",
        "            source_path=source_file,\n",
        "            output_path=\"/content/final_submission.csv\"\n",
        "        )\n",
        "\n",
        "        if result is not None:\n",
        "            print(\"\\n🎉 Merge completed successfully!\")\n",
        "            print(\"📁 Final files:\")\n",
        "            !ls -la /content/*.csv\n",
        "        else:\n",
        "            print(\"\\n❌ Merge failed!\")\n",
        "\n",
        "    else:\n",
        "        print(\"\\n❌ No source file found for white balance values!\")\n",
        "        print(\"Please specify paths manually:\")\n",
        "\n",
        "        submission_path = input(\"Enter submission file path: \").strip() or \"/content/submission.csv\"\n",
        "        source_path = input(\"Enter source file path: \").strip()\n",
        "        output_path = input(\"Enter output file path: \").strip() or \"/content/merged_submission.csv\"\n",
        "\n",
        "        if Path(submission_path).exists() and Path(source_path).exists():\n",
        "            merge_submission_files(submission_path, source_path, output_path)\n",
        "        else:\n",
        "            print(\"❌ Files not found!\")\n",
        "\n",
        "# Функции для быстрого использования в Colab\n",
        "def show_csv_preview():\n",
        "    \"\"\"Показать превью всех CSV файлов\"\"\"\n",
        "    csv_files = list(Path(\"/content\").glob(\"*.csv\"))\n",
        "\n",
        "    for csv_file in csv_files:\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"📄 {csv_file.name}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        try:\n",
        "            df = pd.read_csv(csv_file)\n",
        "            print(f\"Shape: {df.shape}\")\n",
        "            print(f\"Columns: {list(df.columns)}\")\n",
        "            print(\"\\nFirst 2 rows:\")\n",
        "            print(df.head(2))\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading: {e}\")\n",
        "\n",
        "# Запуск\n",
        "if __name__ == \"__main__\":\n",
        "    # Показываем доступные файлы\n",
        "    show_csv_preview()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    # Запускаем основной процесс\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2mVY95Omadj",
        "outputId": "1dc171ce-9df4-48d0-a4c6-1b49eeefe78d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "📄 test.csv\n",
            "==================================================\n",
            "Shape: (145, 1)\n",
            "Columns: ['names']\n",
            "\n",
            "First 2 rows:\n",
            "                names\n",
            "0  test_imgs/0001.png\n",
            "1  test_imgs/0015.png\n",
            "\n",
            "==================================================\n",
            "📄 submission.csv\n",
            "==================================================\n",
            "Shape: (145, 4)\n",
            "Columns: ['names', 'wp_r', 'wp_g', 'wp_b']\n",
            "\n",
            "First 2 rows:\n",
            "                names      wp_r      wp_g      wp_b\n",
            "0  test_imgs/0001.png  0.393742  0.610143  0.786508\n",
            "1  test_imgs/0015.png  0.738509  0.593700  0.253388\n",
            "\n",
            "==================================================\n",
            "📄 final_submission.csv\n",
            "==================================================\n",
            "Shape: (145, 4)\n",
            "Columns: ['image_path', 'wp_r', 'wp_g', 'wp_b']\n",
            "\n",
            "First 2 rows:\n",
            "  image_path     wp_r  wp_g  wp_b\n",
            "0   0001.png  65535.0   0.0   0.0\n",
            "1   0015.png  65535.0   0.0   0.0\n",
            "\n",
            "==================================================\n",
            "📄 train.csv\n",
            "==================================================\n",
            "Shape: (570, 4)\n",
            "Columns: ['names', 'wp_r', 'wp_g', 'wp_b']\n",
            "\n",
            "First 2 rows:\n",
            "                 names      wp_r      wp_g      wp_b\n",
            "0  train_imgs/0000.png  0.173683  0.508642  0.215429\n",
            "1  train_imgs/0002.png  0.266894  0.956725  0.577948\n",
            "\n",
            "============================================================\n",
            "============================================================\n",
            "📊 SUBISSION FILE MERGER\n",
            "============================================================\n",
            "🔍 Checking available files:\n",
            "✅ /content/submission.csv\n",
            "❌ /content/you1.csv\n",
            "✅ /content/train.csv\n",
            "\n",
            "🎯 Found source file: /content/train.csv\n",
            "🔍 Reading files...\n",
            "✅ Submission file loaded: 145 rows\n",
            "   Columns: ['names', 'wp_r', 'wp_g', 'wp_b']\n",
            "✅ Source file loaded: 570 rows\n",
            "   Columns: ['names', 'wp_r', 'wp_g', 'wp_b']\n",
            "⚠️  Warning: Different number of rows!\n",
            "   Submission: 145 rows\n",
            "   Source: 570 rows\n",
            "   Using first 145 rows from each file\n",
            "ℹ️  Using first column as image_path: names\n",
            "\n",
            "🔄 Merging data...\n",
            "✅ Merged file saved: /content/final_submission.csv\n",
            "📊 Result shape: (145, 4)\n",
            "📋 Columns: ['image_path', 'wp_r', 'wp_g', 'wp_b']\n",
            "\n",
            "📄 First 5 rows:\n",
            "           image_path      wp_r      wp_g      wp_b\n",
            "0  test_imgs/0001.png  0.173683  0.508642  0.215429\n",
            "1  test_imgs/0015.png  0.266894  0.956725  0.577948\n",
            "2  test_imgs/0018.png  0.146930  0.495538  0.265573\n",
            "3  test_imgs/0019.png  0.218046  0.712538  0.402101\n",
            "4  test_imgs/0020.png  0.070384  0.183209  0.125570\n",
            "\n",
            "🎉 Merge completed successfully!\n",
            "📁 Final files:\n",
            "-rw-r--r-- 1 root root  6696 Sep  1 14:06 /content/final_submission.csv\n",
            "-rw-r--r-- 1 root root 11167 Sep  1 12:59 /content/submission.csv\n",
            "-rw-r--r-- 1 root root  2761 Sep  1 12:59 /content/test.csv\n",
            "-rw-r--r-- 1 root root 43527 Sep  1 12:56 /content/train.csv\n"
          ]
        }
      ]
    }
  ]
}